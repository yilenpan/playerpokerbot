{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ka98Em5W8LZH"
   },
   "source": [
    "# Poker LLM Tournament\n\nSingle-elimination tournament comparing poker LLMs with **1000 hands per matchup**.\n\n## Models\n| Model | Type | Description |\n|-------|------|-------------|\n| Qwen3-SFT | HuggingFace | `YiPz/qwen3-4b-pokergpt-o3-sft-lora` - Fine-tuned on 5k hands |\n| Qwen3-GRPO | HuggingFace | `YiPz/qwen3-4b-pokerbench-grpo` - GRPO fine-tuned model |\n| Llama3-SFT | HuggingFace | `YiPz/llama3-8b-pokerbench-sft` - From PokerBench paper |\n| GPT-4 | OpenAI API | Only runs if your model beats Llama3 |\n\n## Gauntlet Format (Cost Optimized)\n```\nRound 1: Qwen3-SFT vs Qwen3-GRPO     (compare finetuning approaches)\nRound 2: Winner R1 vs Llama3-SFT     (benchmark test)\nRound 3: Winner R2 vs GPT-4          (only if your model wins R2)\n```\n\n**Winner determined by total chip profit after 1000 hands.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EU5et6U38LZI"
   },
   "source": [
    "## 1. Setup & Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLmH-Plu8LZI"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive for model caching\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q transformers accelerate torch pokerkit\n",
    "!pip install -q tqdm pandas matplotlib openai\n",
    "\n",
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"/content/drive/MyDrive/hf_cache\"\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ER7sIapt8LZI"
   },
   "outputs": [],
   "source": [
    "# Set OpenAI API key from Colab secrets\n",
    "from google.colab import userdata\n",
    "\n",
    "try:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "    print(\"OpenAI API key loaded from secrets\")\n",
    "except:\n",
    "    print(\"Warning: OPENAI_API_KEY not found in secrets. GPT-4 matchup will be skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpBMOrvP8LZJ"
   },
   "source": [
    "## 2. GPU Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rkTbnncy8LZJ"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "\n",
    "def detect_gpu():\n",
    "    \"\"\"Detect GPU and VRAM.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"nvidia-smi\", \"--query-gpu=name,memory.total\", \"--format=csv,noheader,nounits\"],\n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        gpu_name, vram_mb = result.stdout.strip().split(\", \")\n",
    "        vram_gb = float(vram_mb) / 1024\n",
    "    except:\n",
    "        gpu_name, vram_gb = \"Unknown\", 16.0\n",
    "    return gpu_name, vram_gb\n",
    "\n",
    "GPU_NAME, VRAM_GB = detect_gpu()\n",
    "print(f\"GPU: {GPU_NAME} ({VRAM_GB:.0f}GB)\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Check if we have enough VRAM for full weight Llama3-8B (~16GB)\n",
    "if VRAM_GB < 20:\n",
    "    print(f\"\\nWarning: Llama3-8B requires ~16GB VRAM at FP16.\")\n",
    "    print(\"Models will be loaded/unloaded sequentially to manage memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxBmrKxU8LZJ"
   },
   "source": [
    "## 3. Tournament Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZfUB1taB8LZJ"
   },
   "outputs": [],
   "source": [
    "# Tournament settings\nDRY_RUN = True  # Set to False for full 1000-hand matchups\nDRY_RUN_HANDS = 10  # Hands for quick testing\nFULL_RUN_HANDS = 1000  # Hands for full tournament\n\nHANDS_PER_MATCHUP = DRY_RUN_HANDS if DRY_RUN else FULL_RUN_HANDS\n\nSTARTING_STACK = 10000\nSMALL_BLIND = 50\nBIG_BLIND = 100\nSEED = 42\nVERBOSE = False  # Set True to see each action\n\n# Model configurations\nMODELS = {\n    \"Qwen3-SFT\": {\n        \"type\": \"transformers\",\n        \"model_id\": \"YiPz/qwen3-4b-pokergpt-o3-sft-lora\",\n    },\n    \"Qwen3-GRPO\": {\n        \"type\": \"transformers\",\n        \"model_id\": \"YiPz/qwen3-4b-pokerbench-grpo\",\n    },\n    \"Llama3-SFT\": {\n        \"type\": \"transformers\",\n        \"model_id\": \"YiPz/llama3-8b-pokerbench-sft\",\n    },\n    \"GPT-4\": {\n        \"type\": \"openai\",\n        \"model\": \"gpt-4\",\n    },\n}\n\n# Gauntlet order\nGAUNTLET = [\n    (\"Qwen3-SFT\", \"Qwen3-GRPO\"),    # Round 1: Compare finetuning approaches\n    (\"WINNER_R1\", \"Llama3-SFT\"),    # Round 2: vs Benchmark\n    (\"WINNER_R2\", \"GPT-4\"),         # Round 3: vs GPT-4 (conditional)\n]\n\n# Output directory\nOUTPUT_DIR = \"/content/tournament_results\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\nos.makedirs(f\"{OUTPUT_DIR}/observability/traces\", exist_ok=True)\nos.makedirs(f\"{OUTPUT_DIR}/charts\", exist_ok=True)\n\nprint(f\"Tournament Config:\")\nprint(f\"  Mode: {'DRY RUN' if DRY_RUN else 'FULL'}\")\nprint(f\"  Hands per matchup: {HANDS_PER_MATCHUP}\")\nprint(f\"  Stack: {STARTING_STACK}\")\nprint(f\"  Blinds: {SMALL_BLIND}/{BIG_BLIND}\")\nprint(f\"  Output: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qljQDiER8LZJ"
   },
   "source": [
    "## 4. Core Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZzV74WS8LZJ"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "import gc\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from pokerkit import NoLimitTexasHoldem, Automation\n",
    "\n",
    "\n",
    "# ============= Card & Position Utilities =============\n",
    "\n",
    "SUIT_MAP = {\"s\": \"\u2660\", \"h\": \"\u2665\", \"d\": \"\u2666\", \"c\": \"\u2663\"}\n",
    "RANK_ORDER = \"23456789TJQKA\"\n",
    "RANK_VALUE = {r: i for i, r in enumerate(RANK_ORDER, start=2)}\n",
    "\n",
    "\n",
    "def pretty_card(card: str) -> str:\n",
    "    \"\"\"Format a card string with pretty suit symbols. 'As' -> 'A\u2660'\"\"\"\n",
    "    if len(card) < 2:\n",
    "        return card\n",
    "    rank = card[:-1]\n",
    "    suit = SUIT_MAP.get(card[-1].lower(), card[-1])\n",
    "    return f\"{rank}{suit}\"\n",
    "\n",
    "\n",
    "def score_hole_cards(c1: str, c2: str) -> int:\n",
    "    \"\"\"Score preflop hole cards (0-128, where 128 = AA).\"\"\"\n",
    "    r1 = c1[0].upper() if c1 else \"2\"\n",
    "    r2 = c2[0].upper() if c2 else \"2\"\n",
    "    v1 = RANK_VALUE.get(r1, 2)\n",
    "    v2 = RANK_VALUE.get(r2, 2)\n",
    "    high, low = max(v1, v2), min(v1, v2)\n",
    "    is_pair = v1 == v2\n",
    "    is_suited = len(c1) > 1 and len(c2) > 1 and c1[-1].lower() == c2[-1].lower()\n",
    "\n",
    "    if is_pair:\n",
    "        return 100 + high * 2\n",
    "\n",
    "    score = high * 4 + low\n",
    "    if is_suited:\n",
    "        score += 12\n",
    "    gap = high - low\n",
    "    if gap == 1:\n",
    "        score += 6\n",
    "    elif gap == 2:\n",
    "        score += 3\n",
    "    if high >= 11 and low >= 10:\n",
    "        score += 6\n",
    "    if high == 14:\n",
    "        score += 4\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_position_name(player_idx: int, num_players: int, button_idx: int) -> str:\n",
    "    \"\"\"Get position name (UTG, MP, CO, BTN, SB, BB).\"\"\"\n",
    "    if num_players < 2:\n",
    "        return \"Unknown\"\n",
    "    offset = (player_idx - button_idx) % num_players\n",
    "\n",
    "    if num_players == 2:\n",
    "        return \"BTN/SB\" if offset == 0 else \"BB\"\n",
    "    if offset == 0:\n",
    "        return \"BTN\"\n",
    "    elif offset == 1:\n",
    "        return \"SB\"\n",
    "    elif offset == 2:\n",
    "        return \"BB\"\n",
    "\n",
    "    if num_players == 4:\n",
    "        if offset == 3: return \"CO\"\n",
    "    elif num_players == 5:\n",
    "        if offset == 3: return \"MP\"\n",
    "        elif offset == 4: return \"CO\"\n",
    "    elif num_players == 6:\n",
    "        if offset == 3: return \"UTG\"\n",
    "        elif offset == 4: return \"MP\"\n",
    "        elif offset == 5: return \"CO\"\n",
    "    elif num_players >= 7:\n",
    "        positions = [\"BTN\", \"SB\", \"BB\", \"UTG\", \"UTG+1\", \"MP\", \"MP+1\", \"HJ\", \"CO\"]\n",
    "        if offset < len(positions):\n",
    "            return positions[offset]\n",
    "\n",
    "    return f\"P{player_idx + 1}\"\n",
    "\n",
    "\n",
    "# ============= Action Parsing =============\n",
    "\n",
    "@dataclass\n",
    "class ParsedAction:\n",
    "    action_type: str\n",
    "    amount: Optional[int] = None\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.amount:\n",
    "            return f\"{self.action_type.title()} {self.amount}\"\n",
    "        return self.action_type.title()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ParseResult:\n",
    "    action: ParsedAction\n",
    "    method: str  # \"tag\" | \"regex_*\" | \"default\"\n",
    "    raw_match: str\n",
    "    error: Optional[str] = None\n",
    "\n",
    "\n",
    "class ActionParser:\n",
    "    RE_ACTION_TAG = re.compile(r\"<action>\\s*([^<]+?)\\s*</action>\", re.IGNORECASE)\n",
    "    RE_FOLD = re.compile(r\"\\b(f|fold)\\b\", re.IGNORECASE)\n",
    "    RE_CC = re.compile(r\"\\b(cc|call|check)\\b\", re.IGNORECASE)\n",
    "    RE_CBR = re.compile(r\"\\b(?:cbr|bet|raise)(?:\\s+(?:to\\s+)?(\\d+))?\\b\", re.IGNORECASE)\n",
    "    RE_ALL_IN = re.compile(r\"\\b(all[\\-\\s]?in|shove)\\b\", re.IGNORECASE)\n",
    "\n",
    "    def parse(self, text: str, can_check: bool = True, stack: int = 0) -> ParsedAction:\n",
    "        return self.parse_with_metadata(text, can_check, stack).action\n",
    "\n",
    "    def parse_with_metadata(self, text: str, can_check: bool = True, stack: int = 0) -> ParseResult:\n",
    "        tag_match = self.RE_ACTION_TAG.search(text)\n",
    "        used_tag = tag_match is not None\n",
    "        content = tag_match.group(1).strip() if tag_match else text\n",
    "\n",
    "        if self.RE_ALL_IN.search(content):\n",
    "            return ParseResult(ParsedAction(\"all_in\", stack), \"tag\" if used_tag else \"regex_allin\", content)\n",
    "        if self.RE_FOLD.search(content):\n",
    "            return ParseResult(ParsedAction(\"fold\"), \"tag\" if used_tag else \"regex_fold\", content)\n",
    "        if self.RE_CC.search(content):\n",
    "            action = ParsedAction(\"check\" if can_check else \"call\")\n",
    "            return ParseResult(action, \"tag\" if used_tag else \"regex_call\", content)\n",
    "\n",
    "        cbr = self.RE_CBR.search(content)\n",
    "        if cbr:\n",
    "            amt = int(cbr.group(1)) if cbr.group(1) else stack\n",
    "            return ParseResult(ParsedAction(\"raise\", amt), \"tag\" if used_tag else \"regex_raise\", content)\n",
    "\n",
    "        default_action = ParsedAction(\"check\" if can_check else \"fold\")\n",
    "        return ParseResult(default_action, \"default\", content[:100], \"No valid action pattern found\")\n",
    "\n",
    "\n",
    "# ============= Action Record =============\n",
    "\n",
    "@dataclass\n",
    "class ActionRecord:\n",
    "    hand_id: int\n",
    "    street: str\n",
    "    hole_cards: Tuple[str, str]\n",
    "    board: List[str]\n",
    "    pot: int\n",
    "    to_call: int\n",
    "    stack: int\n",
    "    position: str\n",
    "    action: ParsedAction\n",
    "    thinking: str\n",
    "    response: str\n",
    "    latency_ms: float\n",
    "    tokens_generated: int\n",
    "    parse_method: str = \"unknown\"\n",
    "    parse_error: Optional[str] = None\n",
    "\n",
    "\n",
    "# ============= PromptBuilder (pokergpt format) =============\n",
    "\n",
    "class PromptBuilder:\n",
    "    \"\"\"Builds prompts in pokergpt format for LLM poker players.\"\"\"\n",
    "\n",
    "    def __init__(self, big_blind: int = 100):\n",
    "        self.big_blind = big_blind\n",
    "        self.action_history: List[str] = []\n",
    "\n",
    "    def record_deal(self, player_label: str, is_hero: bool = False, blind_note: str = \"\"):\n",
    "        \"\"\"Record a hole card deal.\"\"\"\n",
    "        suffix = f\" ({blind_note})\" if blind_note else \"\"\n",
    "        if is_hero:\n",
    "            self.action_history.append(f\"{player_label} were dealt your hole cards{suffix}.\")\n",
    "        else:\n",
    "            self.action_history.append(f\"{player_label} was dealt hole cards{suffix}.\")\n",
    "\n",
    "    def record_board(self, board_cards: List[str]):\n",
    "        \"\"\"Record a board deal.\"\"\"\n",
    "        n = len(board_cards)\n",
    "        if n == 3:\n",
    "            street = \"Flop\"\n",
    "        elif n == 4:\n",
    "            street = \"Turn\"\n",
    "        elif n == 5:\n",
    "            street = \"River\"\n",
    "        else:\n",
    "            street = \"Board\"\n",
    "        pretty = \" \".join(pretty_card(c) for c in board_cards)\n",
    "        self.action_history.append(f\"{street} dealt: {pretty}\")\n",
    "\n",
    "    def record_action(self, player_label: str, action: str, amount_bb: Optional[float] = None):\n",
    "        \"\"\"Record a player action.\"\"\"\n",
    "        if amount_bb is not None:\n",
    "            self.action_history.append(f\"{player_label} {action} {amount_bb:.1f} BB.\")\n",
    "        else:\n",
    "            self.action_history.append(f\"{player_label} {action}.\")\n",
    "\n",
    "    def reset_hand(self):\n",
    "        \"\"\"Reset action history for a new hand.\"\"\"\n",
    "        self.action_history = []\n",
    "\n",
    "    def get_player_label(self, player_idx: int, hero_idx: int, positions: List[str]) -> str:\n",
    "        \"\"\"Get label for a player.\"\"\"\n",
    "        pos = positions[player_idx] if player_idx < len(positions) else f\"P{player_idx + 1}\"\n",
    "        if player_idx == hero_idx:\n",
    "            return f\"You ({pos})\"\n",
    "        return pos\n",
    "\n",
    "    def build_prompt(\n",
    "        self,\n",
    "        hero_idx: int,\n",
    "        hero_cards: Tuple[str, str],\n",
    "        board: List[str],\n",
    "        stacks: List[int],\n",
    "        bets: List[int],\n",
    "        pot: int,\n",
    "        to_call: int,\n",
    "        min_raise: int,\n",
    "        button_idx: int,\n",
    "        num_players: int,\n",
    "        street: str = \"preflop\",\n",
    "    ) -> str:\n",
    "        \"\"\"Build a prompt in pokergpt format.\"\"\"\n",
    "        bb = self.big_blind\n",
    "        positions = [get_position_name(i, num_players, button_idx) for i in range(num_players)]\n",
    "        hero_pos = positions[hero_idx]\n",
    "\n",
    "        lines = [\n",
    "            \"You are an expert poker player and you are playing NT poker.\",\n",
    "            f\"There are {num_players} players at the table.\",\n",
    "            f\"You are in the {hero_pos} position.\",\n",
    "            \"\",\n",
    "            \"Stacks:\",\n",
    "        ]\n",
    "\n",
    "        for i, stack in enumerate(stacks):\n",
    "            label = self.get_player_label(i, hero_idx, positions)\n",
    "            lines.append(f\"- {label}: {stack / bb:.1f} BB\")\n",
    "\n",
    "        if self.action_history:\n",
    "            lines.extend([\"\", \"Actions so far:\"])\n",
    "            for action in self.action_history:\n",
    "                lines.append(f\"- {action}\")\n",
    "\n",
    "        c1, c2 = hero_cards\n",
    "        lines.extend([\n",
    "            \"\",\n",
    "            f\"Your hole cards are: {pretty_card(c1)} {pretty_card(c2)}\",\n",
    "        ])\n",
    "\n",
    "        if street == \"preflop\":\n",
    "            strength = score_hole_cards(c1, c2)\n",
    "            lines.append(f\"Preflop hand strength score out of 128 (128 is pair Aces): {strength}\")\n",
    "        elif board:\n",
    "            pretty_board = \" \".join(pretty_card(c) for c in board)\n",
    "            lines.append(f\"The current board is: {pretty_board}\")\n",
    "\n",
    "        if any(b > 0 for b in bets):\n",
    "            lines.extend([\"\", \"The current bets are:\"])\n",
    "            for i, bet in enumerate(bets):\n",
    "                if bet > 0:\n",
    "                    label = self.get_player_label(i, hero_idx, positions)\n",
    "                    lines.append(f\"- {label}: {bet / bb:.1f} BB\")\n",
    "\n",
    "        lines.extend([\n",
    "            \"\",\n",
    "            f\"The current pot size is: {pot / bb:.1f} BB\",\n",
    "            \"It is now your turn to act.\",\n",
    "            \"Minimum bet: 1 BB.\",\n",
    "            \"\",\n",
    "            \"Available actions:\",\n",
    "        ])\n",
    "\n",
    "        if to_call > 0:\n",
    "            lines.append(\"- Fold\")\n",
    "            lines.append(f\"- Call {to_call / bb:.0f} BB\")\n",
    "            lines.append(f\"- Raise (minimum: {min_raise / bb:.0f} BB)\")\n",
    "        else:\n",
    "            lines.append(\"- Check\")\n",
    "            lines.append(\"- Bet (minimum: 1 BB)\")\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "print(\"Core classes loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ============= Unit Tests: Action Parsing =============\n",
    "print(\"Testing ActionParser...\")\n",
    "\n",
    "parser = ActionParser()\n",
    "\n",
    "# Valid tag formats\n",
    "assert parser.parse(\"<action>f</action>\").action_type == \"fold\"\n",
    "assert parser.parse(\"<action>cc</action>\", can_check=True).action_type == \"check\"\n",
    "assert parser.parse(\"<action>cc</action>\", can_check=False).action_type == \"call\"\n",
    "assert parser.parse(\"<action>cbr 500</action>\").action_type == \"raise\"\n",
    "assert parser.parse(\"<action>cbr 500</action>\").amount == 500\n",
    "\n",
    "# Regex fallbacks (no tags)\n",
    "assert parser.parse(\"I fold\").action_type == \"fold\"\n",
    "assert parser.parse(\"call\").action_type == \"call\"\n",
    "assert parser.parse(\"raise to 300\").action_type == \"raise\"\n",
    "assert parser.parse(\"all in\", stack=1000).action_type == \"all_in\"\n",
    "\n",
    "# Edge cases\n",
    "assert parser.parse(\"\", can_check=True).action_type == \"check\"  # Empty defaults to check\n",
    "assert parser.parse(\"gibberish text\", can_check=False).action_type == \"fold\"  # Defaults to fold\n",
    "\n",
    "print(\"\u2713 ActionParser tests passed!\")"
   ],
   "metadata": {
    "id": "CsFlzis08LZK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ============= Unit Tests: PromptBuilder =============\n",
    "print(\"Testing PromptBuilder...\")\n",
    "\n",
    "pb = PromptBuilder(big_blind=100)\n",
    "prompt = pb.build_prompt(\n",
    "    hero_idx=0, hero_cards=(\"As\", \"Kh\"), board=[],\n",
    "    stacks=[10000, 10000], bets=[50, 100], pot=150,\n",
    "    to_call=50, min_raise=200, button_idx=0,\n",
    "    num_players=2, street=\"preflop\"\n",
    ")\n",
    "\n",
    "# Check key elements in prompt\n",
    "assert \"expert poker player\" in prompt.lower(), \"Missing intro text\"\n",
    "assert \"2 players\" in prompt.lower() or \"2-handed\" in prompt.lower(), \"Missing player count\"\n",
    "assert \"preflop\" in prompt.lower() or \"hole cards\" in prompt.lower(), \"Missing street context\"\n",
    "\n",
    "# Check card formatting (should have suit symbols)\n",
    "assert \"\u2660\" in prompt or \"A\" in prompt, \"Missing card info\"\n",
    "\n",
    "# Check BB units are used\n",
    "assert \"BB\" in prompt, \"Missing BB units\"\n",
    "\n",
    "# Test with board cards (postflop)\n",
    "pb.reset_hand()\n",
    "prompt_flop = pb.build_prompt(\n",
    "    hero_idx=0, hero_cards=(\"As\", \"Kh\"), board=[\"Ah\", \"7c\", \"2d\"],\n",
    "    stacks=[9500, 9500], bets=[0, 0], pot=500,\n",
    "    to_call=0, min_raise=100, button_idx=0,\n",
    "    num_players=2, street=\"flop\"\n",
    ")\n",
    "assert \"board\" in prompt_flop.lower() or \"flop\" in prompt_flop.lower(), \"Missing board in flop prompt\"\n",
    "\n",
    "print(\"\u2713 PromptBuilder tests passed!\")"
   ],
   "metadata": {
    "id": "O6nLWSKk8LZK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oFxcaJK28LZK"
   },
   "outputs": [],
   "source": [
    "# ============= Observability =============\n",
    "\n",
    "@dataclass\n",
    "class ModelObservability:\n",
    "    model_name: str\n",
    "    total_actions: int = 0\n",
    "    valid_tag_parses: int = 0\n",
    "    regex_fallback_parses: int = 0\n",
    "    default_fallback_parses: int = 0\n",
    "    action_execution_failures: int = 0\n",
    "    empty_responses: int = 0\n",
    "    fold_count: int = 0\n",
    "    check_count: int = 0\n",
    "    call_count: int = 0\n",
    "    raise_count: int = 0\n",
    "    all_in_count: int = 0\n",
    "    latencies: List[float] = field(default_factory=list)\n",
    "    total_tokens: int = 0\n",
    "\n",
    "    @property\n",
    "    def parse_error_rate(self) -> float:\n",
    "        if self.total_actions == 0:\n",
    "            return 0.0\n",
    "        return (self.regex_fallback_parses + self.default_fallback_parses) / self.total_actions\n",
    "\n",
    "    @property\n",
    "    def avg_latency_ms(self) -> float:\n",
    "        return sum(self.latencies) / len(self.latencies) if self.latencies else 0.0\n",
    "\n",
    "    @property\n",
    "    def p99_latency_ms(self) -> float:\n",
    "        if not self.latencies:\n",
    "            return 0.0\n",
    "        sorted_lat = sorted(self.latencies)\n",
    "        return sorted_lat[int(len(sorted_lat) * 0.99)]\n",
    "\n",
    "\n",
    "class ObservabilityCollector:\n",
    "    def __init__(self, output_dir: str):\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.traces: Dict[str, List[dict]] = {}\n",
    "        self.metrics: Dict[str, ModelObservability] = {}\n",
    "\n",
    "    def record_action(self, model_name: str, record: ActionRecord, executed_action: str, fallback_used: bool):\n",
    "        # Store trace\n",
    "        if model_name not in self.traces:\n",
    "            self.traces[model_name] = []\n",
    "\n",
    "        trace = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"hand_id\": record.hand_id,\n",
    "            \"street\": record.street,\n",
    "            \"hole_cards\": list(record.hole_cards),\n",
    "            \"board\": record.board,\n",
    "            \"pot\": record.pot,\n",
    "            \"to_call\": record.to_call,\n",
    "            \"stack\": record.stack,\n",
    "            \"position\": record.position,\n",
    "            \"raw_response\": record.response,\n",
    "            \"thinking\": record.thinking,\n",
    "            \"parsed_action\": record.action.action_type,\n",
    "            \"parsed_amount\": record.action.amount,\n",
    "            \"parse_method\": record.parse_method,\n",
    "            \"parse_error\": record.parse_error,\n",
    "            \"executed_action\": executed_action,\n",
    "            \"fallback_used\": fallback_used,\n",
    "            \"latency_ms\": record.latency_ms,\n",
    "            \"tokens\": record.tokens_generated,\n",
    "        }\n",
    "        self.traces[model_name].append(trace)\n",
    "\n",
    "        # Update metrics\n",
    "        if model_name not in self.metrics:\n",
    "            self.metrics[model_name] = ModelObservability(model_name=model_name)\n",
    "        m = self.metrics[model_name]\n",
    "\n",
    "        m.total_actions += 1\n",
    "        m.latencies.append(record.latency_ms)\n",
    "        m.total_tokens += record.tokens_generated\n",
    "\n",
    "        if record.parse_method == \"tag\":\n",
    "            m.valid_tag_parses += 1\n",
    "        elif record.parse_method.startswith(\"regex\"):\n",
    "            m.regex_fallback_parses += 1\n",
    "        elif record.parse_method == \"default\":\n",
    "            m.default_fallback_parses += 1\n",
    "\n",
    "        if not record.response.strip():\n",
    "            m.empty_responses += 1\n",
    "        if fallback_used:\n",
    "            m.action_execution_failures += 1\n",
    "\n",
    "        action = executed_action.lower()\n",
    "        if action == \"fold\": m.fold_count += 1\n",
    "        elif action == \"check\": m.check_count += 1\n",
    "        elif action == \"call\": m.call_count += 1\n",
    "        elif action == \"raise\": m.raise_count += 1\n",
    "        elif action == \"all_in\": m.all_in_count += 1\n",
    "\n",
    "    def write_traces(self, matchup_id: str):\n",
    "        traces_dir = self.output_dir / \"observability\" / \"traces\"\n",
    "        traces_dir.mkdir(parents=True, exist_ok=True)\n",
    "        for model_name, traces in self.traces.items():\n",
    "            safe_name = model_name.replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "            filepath = traces_dir / f\"{safe_name}_{matchup_id}.jsonl\"\n",
    "            with open(filepath, \"w\") as f:\n",
    "                for trace in traces:\n",
    "                    f.write(json.dumps(trace) + \"\\n\")\n",
    "\n",
    "    def export_metrics(self):\n",
    "        metrics_path = self.output_dir / \"observability\" / \"model_metrics.json\"\n",
    "        data = {}\n",
    "        for name, m in self.metrics.items():\n",
    "            data[name] = {\n",
    "                \"total_actions\": m.total_actions,\n",
    "                \"valid_tag_parses\": m.valid_tag_parses,\n",
    "                \"regex_fallback_parses\": m.regex_fallback_parses,\n",
    "                \"default_fallback_parses\": m.default_fallback_parses,\n",
    "                \"parse_error_rate\": round(m.parse_error_rate, 4),\n",
    "                \"empty_responses\": m.empty_responses,\n",
    "                \"action_execution_failures\": m.action_execution_failures,\n",
    "                \"action_distribution\": {\n",
    "                    \"fold\": m.fold_count, \"check\": m.check_count,\n",
    "                    \"call\": m.call_count, \"raise\": m.raise_count, \"all_in\": m.all_in_count,\n",
    "                },\n",
    "                \"avg_latency_ms\": round(m.avg_latency_ms, 2),\n",
    "                \"p99_latency_ms\": round(m.p99_latency_ms, 2),\n",
    "                \"total_tokens\": m.total_tokens,\n",
    "            }\n",
    "        with open(metrics_path, \"w\") as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "\n",
    "    def clear(self):\n",
    "        self.traces = {}\n",
    "        self.metrics = {}\n",
    "\n",
    "\n",
    "print(\"Observability loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bi4AwBKQ8LZK"
   },
   "outputs": [],
   "source": [
    "# ============= TransformersPlayer =============\n",
    "\n",
    "class TransformersPlayer:\n",
    "    SYSTEM_PROMPT = \"\"\"\n",
    "    You are an expert poker coach. Analyze the situation and provide your recommended action.\n",
    "\n",
    "PHH Format Actions:\n",
    "- 'f' = fold (give up the hand)\n",
    "- 'cc' = check OR call (use for BOTH - never include an amount)\n",
    "- 'cbr X' = bet or raise TO X big blinds (only when YOU are betting/raising)\n",
    "\n",
    "IMPORTANT:\n",
    "- To CALL any bet (regardless of size), always use just 'cc' with NO amount\n",
    "- 'cbr' is ONLY for when YOU initiate a bet or raise, not for calling\n",
    "- Do NOT include prefixes like 'phh', 'p1', 'p6' etc - just the action\n",
    "- Invalid formats are penalized\n",
    "\n",
    "Always output your final action inside <action></action> tags.\n",
    "\n",
    "Valid examples:\n",
    "- <action>f</action>\n",
    "- <action>cc</action>\n",
    "- <action>cbr 5</action>\n",
    "\n",
    "Invalid examples (DO NOT use):\n",
    "- <action>phh cc</action>\n",
    "- <action>p6 cbr 5</action>\n",
    "- <action>cc 29</action>\n",
    "- <action>cbr 0</action>\n",
    "\n",
    "Think step by step, then output exactly ONE action tag.\"\"\"\n",
    "\n",
    "    THINK_END_TOKEN_ID = 151668\n",
    "\n",
    "    def __init__(self, name: str, model: Any, tokenizer: Any, temperature: float = 0.6, max_new_tokens: int = 2096, big_blind: int = 100):\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.temperature = temperature\n",
    "        self.max_new_tokens = max_new_tokens\n",
    "        self.big_blind = big_blind\n",
    "        self.parser = ActionParser()\n",
    "        self.action_history: List[ActionRecord] = []\n",
    "        self._hand_id = 0\n",
    "        self._street = \"preflop\"\n",
    "\n",
    "        # PromptBuilder for consistent prompt format\n",
    "        self.prompt_builder = PromptBuilder(big_blind=big_blind)\n",
    "\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    def set_hand_context(self, hand_id: int, street: str):\n",
    "        self._hand_id = hand_id\n",
    "        self._street = street\n",
    "        # Reset prompt builder for new hand\n",
    "        if street == \"preflop\":\n",
    "            self.prompt_builder.reset_hand()\n",
    "\n",
    "    def get_action(self, hole_cards, board, pot, to_call, stack, position, num_players) -> ParsedAction:\n",
    "        \"\"\"Get action using PromptBuilder format.\"\"\"\n",
    "        start = time.perf_counter()\n",
    "        prompt = self._build_simple_prompt(hole_cards, board, pot, to_call, stack, position, num_players)\n",
    "\n",
    "        try:\n",
    "            thinking, response, tokens_gen = self._generate(prompt)\n",
    "            can_check = to_call == 0\n",
    "            result = self.parser.parse_with_metadata(response, can_check, stack)\n",
    "            action = result.action\n",
    "            parse_method = result.method\n",
    "            parse_error = result.error\n",
    "        except Exception as e:\n",
    "            thinking, response, tokens_gen = \"\", f\"ERROR: {e}\", 0\n",
    "            action = ParsedAction(\"fold\")\n",
    "            parse_method = \"error\"\n",
    "            parse_error = str(e)\n",
    "\n",
    "        latency = (time.perf_counter() - start) * 1000\n",
    "\n",
    "        self.action_history.append(ActionRecord(\n",
    "            hand_id=self._hand_id, street=self._street, hole_cards=hole_cards,\n",
    "            board=list(board), pot=pot, to_call=to_call, stack=stack,\n",
    "            position=position, action=action, thinking=thinking[:1000],\n",
    "            response=response[:500], latency_ms=latency, tokens_generated=tokens_gen,\n",
    "            parse_method=parse_method, parse_error=parse_error,\n",
    "        ))\n",
    "        return action\n",
    "\n",
    "    def get_action_with_prompt(self, prompt_text: str, hole_cards, board, pot, to_call, stack, position) -> ParsedAction:\n",
    "        \"\"\"Get action using a pre-built prompt (pokergpt format).\"\"\"\n",
    "        start = time.perf_counter()\n",
    "\n",
    "        # Format as chat with system prompt\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": prompt_text},\n",
    "        ]\n",
    "        full_prompt = self.tokenizer.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            thinking, response, tokens_gen = self._generate(full_prompt)\n",
    "            can_check = to_call == 0\n",
    "            result = self.parser.parse_with_metadata(response, can_check, stack)\n",
    "            action = result.action\n",
    "            parse_method = result.method\n",
    "            parse_error = result.error\n",
    "        except Exception as e:\n",
    "            thinking, response, tokens_gen = \"\", f\"ERROR: {e}\", 0\n",
    "            action = ParsedAction(\"fold\")\n",
    "            parse_method = \"error\"\n",
    "            parse_error = str(e)\n",
    "\n",
    "        latency = (time.perf_counter() - start) * 1000\n",
    "\n",
    "        self.action_history.append(ActionRecord(\n",
    "            hand_id=self._hand_id, street=self._street, hole_cards=hole_cards,\n",
    "            board=list(board), pot=pot, to_call=to_call, stack=stack,\n",
    "            position=position, action=action, thinking=thinking[:1000],\n",
    "            response=response[:500], latency_ms=latency, tokens_generated=tokens_gen,\n",
    "            parse_method=parse_method, parse_error=parse_error,\n",
    "        ))\n",
    "        return action\n",
    "\n",
    "    def _build_simple_prompt(self, hole_cards, board, pot, to_call, stack, position, num_players) -> str:\n",
    "        \"\"\"Build pokergpt-style prompt using PromptBuilder format.\"\"\"\n",
    "        bb = self.big_blind\n",
    "\n",
    "        # Build pokergpt format prompt\n",
    "        lines = [\n",
    "            \"You are an expert poker player and you are playing NT poker.\",\n",
    "            f\"There are {num_players} players at the table.\",\n",
    "            f\"You are in the {position} position.\",\n",
    "            \"\",\n",
    "            f\"Your stack: {stack / bb:.1f} BB\",\n",
    "        ]\n",
    "\n",
    "        c1, c2 = hole_cards\n",
    "        lines.extend([\n",
    "            \"\",\n",
    "            f\"Your hole cards are: {pretty_card(c1)} {pretty_card(c2)}\",\n",
    "        ])\n",
    "\n",
    "        if self._street == \"preflop\":\n",
    "            strength = score_hole_cards(c1, c2)\n",
    "            lines.append(f\"Preflop hand strength score out of 128 (128 is pair Aces): {strength}\")\n",
    "        elif board:\n",
    "            pretty_board = \" \".join(pretty_card(c) for c in board)\n",
    "            lines.append(f\"The current board is: {pretty_board}\")\n",
    "\n",
    "        lines.extend([\n",
    "            \"\",\n",
    "            f\"The current pot size is: {pot / bb:.1f} BB\",\n",
    "            \"It is now your turn to act.\",\n",
    "            \"Minimum bet: 1 BB.\",\n",
    "            \"\",\n",
    "            \"Available actions:\",\n",
    "        ])\n",
    "\n",
    "        if to_call > 0:\n",
    "            lines.append(\"- Fold\")\n",
    "            lines.append(f\"- Call {to_call / bb:.1f} BB\")\n",
    "            lines.append(f\"- Raise (minimum: {(to_call + bb) / bb:.1f} BB)\")\n",
    "        else:\n",
    "            lines.append(\"- Check\")\n",
    "            lines.append(\"- Bet (minimum: 1 BB)\")\n",
    "\n",
    "        user_msg = \"\\n\".join(lines)\n",
    "        messages = [{\"role\": \"system\", \"content\": self.SYSTEM_PROMPT}, {\"role\": \"user\", \"content\": user_msg}]\n",
    "        return self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    def _generate(self, prompt: str) -> Tuple[str, str, int]:\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
    "        input_len = inputs.input_ids.shape[1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs, max_new_tokens=self.max_new_tokens, temperature=self.temperature,\n",
    "                top_p=0.95, top_k=20, do_sample=True, pad_token_id=self.tokenizer.pad_token_id,\n",
    "            )\n",
    "\n",
    "        new_tokens = outputs[0][input_len:]\n",
    "        num_tokens = len(new_tokens)\n",
    "\n",
    "        try:\n",
    "            think_end_idx = (new_tokens == self.THINK_END_TOKEN_ID).nonzero(as_tuple=True)[0][-1].item()\n",
    "            thinking_tokens = new_tokens[:think_end_idx]\n",
    "            response_tokens = new_tokens[think_end_idx + 1:]\n",
    "        except:\n",
    "            thinking_tokens = torch.tensor([], dtype=new_tokens.dtype)\n",
    "            response_tokens = new_tokens\n",
    "\n",
    "        thinking = self.tokenizer.decode(thinking_tokens, skip_special_tokens=True).strip()\n",
    "        response = self.tokenizer.decode(response_tokens, skip_special_tokens=True).strip()\n",
    "        return thinking, response, num_tokens\n",
    "\n",
    "    def get_stats(self) -> dict:\n",
    "        if not self.action_history:\n",
    "            return {}\n",
    "        total = len(self.action_history)\n",
    "        preflop = [a for a in self.action_history if a.street == \"preflop\"]\n",
    "        vpip = len([a for a in preflop if a.action.action_type in (\"call\", \"raise\", \"all_in\")]) / len(preflop) if preflop else 0\n",
    "        pfr = len([a for a in preflop if a.action.action_type in (\"raise\", \"all_in\")]) / len(preflop) if preflop else 0\n",
    "        return {\n",
    "            \"total_actions\": total, \"vpip\": vpip, \"pfr\": pfr,\n",
    "            \"avg_latency_ms\": sum(a.latency_ms for a in self.action_history) / total,\n",
    "            \"fold_pct\": sum(1 for a in self.action_history if a.action.action_type == \"fold\") / total,\n",
    "        }\n",
    "\n",
    "    def get_last_record(self) -> Optional[ActionRecord]:\n",
    "        return self.action_history[-1] if self.action_history else None\n",
    "\n",
    "    def reset_history(self):\n",
    "        self.action_history = []\n",
    "\n",
    "\n",
    "print(\"TransformersPlayer loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVlJfm0d8LZK"
   },
   "outputs": [],
   "source": [
    "# ============= OpenAIPlayer =============\n",
    "\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "    OPENAI_AVAILABLE = True\n",
    "except ImportError:\n",
    "    OPENAI_AVAILABLE = False\n",
    "\n",
    "\n",
    "class OpenAIPlayer:\n",
    "    SYSTEM_PROMPT = TransformersPlayer.SYSTEM_PROMPT  # Same prompt\n",
    "\n",
    "    def __init__(self, name: str, model: str = \"gpt-4\", temperature: float = 0.6, max_tokens: int = 512):\n",
    "        if not OPENAI_AVAILABLE:\n",
    "            raise ImportError(\"openai package not installed\")\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.client = OpenAI()\n",
    "        self.parser = ActionParser()\n",
    "        self.action_history: List[ActionRecord] = []\n",
    "        self._hand_id = 0\n",
    "        self._street = \"preflop\"\n",
    "        self.total_input_tokens = 0\n",
    "        self.total_output_tokens = 0\n",
    "\n",
    "    def set_hand_context(self, hand_id: int, street: str):\n",
    "        self._hand_id = hand_id\n",
    "        self._street = street\n",
    "\n",
    "    def get_action(self, hole_cards, board, pot, to_call, stack, position, num_players) -> ParsedAction:\n",
    "        \"\"\"Get action using simple prompt (fallback).\"\"\"\n",
    "        start = time.perf_counter()\n",
    "        user_msg = self._build_simple_prompt(hole_cards, board, pot, to_call, stack, position, num_players)\n",
    "\n",
    "        try:\n",
    "            response_text, tokens_in, tokens_out = self._call_api(user_msg)\n",
    "            can_check = to_call == 0\n",
    "            result = self.parser.parse_with_metadata(response_text, can_check, stack)\n",
    "            action = result.action\n",
    "            parse_method = result.method\n",
    "            parse_error = result.error\n",
    "        except Exception as e:\n",
    "            response_text = f\"ERROR: {e}\"\n",
    "            tokens_in = tokens_out = 0\n",
    "            action = ParsedAction(\"fold\")\n",
    "            parse_method = \"error\"\n",
    "            parse_error = str(e)\n",
    "\n",
    "        latency = (time.perf_counter() - start) * 1000\n",
    "\n",
    "        self.action_history.append(ActionRecord(\n",
    "            hand_id=self._hand_id, street=self._street, hole_cards=hole_cards,\n",
    "            board=list(board), pot=pot, to_call=to_call, stack=stack,\n",
    "            position=position, action=action, thinking=\"\",\n",
    "            response=response_text[:500], latency_ms=latency, tokens_generated=tokens_out,\n",
    "            parse_method=parse_method, parse_error=parse_error,\n",
    "        ))\n",
    "        return action\n",
    "\n",
    "    def get_action_with_prompt(self, prompt_text: str, hole_cards, board, pot, to_call, stack, position) -> ParsedAction:\n",
    "        \"\"\"Get action using a pre-built prompt (pokergpt format).\"\"\"\n",
    "        start = time.perf_counter()\n",
    "\n",
    "        try:\n",
    "            response_text, tokens_in, tokens_out = self._call_api(prompt_text)\n",
    "            can_check = to_call == 0\n",
    "            result = self.parser.parse_with_metadata(response_text, can_check, stack)\n",
    "            action = result.action\n",
    "            parse_method = result.method\n",
    "            parse_error = result.error\n",
    "        except Exception as e:\n",
    "            response_text = f\"ERROR: {e}\"\n",
    "            tokens_in = tokens_out = 0\n",
    "            action = ParsedAction(\"fold\")\n",
    "            parse_method = \"error\"\n",
    "            parse_error = str(e)\n",
    "\n",
    "        latency = (time.perf_counter() - start) * 1000\n",
    "\n",
    "        self.action_history.append(ActionRecord(\n",
    "            hand_id=self._hand_id, street=self._street, hole_cards=hole_cards,\n",
    "            board=list(board), pot=pot, to_call=to_call, stack=stack,\n",
    "            position=position, action=action, thinking=\"\",\n",
    "            response=response_text[:500], latency_ms=latency, tokens_generated=tokens_out,\n",
    "            parse_method=parse_method, parse_error=parse_error,\n",
    "        ))\n",
    "        return action\n",
    "\n",
    "    def _build_simple_prompt(self, hole_cards, board, pot, to_call, stack, position, num_players) -> str:\n",
    "        \"\"\"Build simple prompt (fallback).\"\"\"\n",
    "        board_str = \" \".join(board) if board else \"None\"\n",
    "        return f\"\"\"Game: {num_players}-handed No-Limit Hold'em\n",
    "Position: {position}\n",
    "Stack: {stack}\n",
    "Hole Cards: {hole_cards[0]} {hole_cards[1]}\n",
    "Board: {board_str}\n",
    "Pot: {pot}\n",
    "To Call: {to_call}\n",
    "\n",
    "What is your action?\"\"\"\n",
    "\n",
    "    def _call_api(self, user_msg: str) -> Tuple[str, int, int]:\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": user_msg},\n",
    "            ],\n",
    "            temperature=self.temperature,\n",
    "            max_tokens=self.max_tokens,\n",
    "        )\n",
    "        content = response.choices[0].message.content or \"\"\n",
    "        tokens_in = response.usage.prompt_tokens if response.usage else 0\n",
    "        tokens_out = response.usage.completion_tokens if response.usage else 0\n",
    "        self.total_input_tokens += tokens_in\n",
    "        self.total_output_tokens += tokens_out\n",
    "        return content, tokens_in, tokens_out\n",
    "\n",
    "    def get_stats(self) -> dict:\n",
    "        if not self.action_history:\n",
    "            return {}\n",
    "        total = len(self.action_history)\n",
    "        preflop = [a for a in self.action_history if a.street == \"preflop\"]\n",
    "        vpip = len([a for a in preflop if a.action.action_type in (\"call\", \"raise\", \"all_in\")]) / len(preflop) if preflop else 0\n",
    "        pfr = len([a for a in preflop if a.action.action_type in (\"raise\", \"all_in\")]) / len(preflop) if preflop else 0\n",
    "        return {\n",
    "            \"total_actions\": total, \"vpip\": vpip, \"pfr\": pfr,\n",
    "            \"avg_latency_ms\": sum(a.latency_ms for a in self.action_history) / total,\n",
    "            \"fold_pct\": sum(1 for a in self.action_history if a.action.action_type == \"fold\") / total,\n",
    "            \"total_input_tokens\": self.total_input_tokens,\n",
    "            \"total_output_tokens\": self.total_output_tokens,\n",
    "        }\n",
    "\n",
    "    def get_last_record(self) -> Optional[ActionRecord]:\n",
    "        return self.action_history[-1] if self.action_history else None\n",
    "\n",
    "    def get_estimated_cost(self) -> float:\n",
    "        if \"turbo\" in self.model.lower() or \"4o\" in self.model.lower():\n",
    "            return self.total_input_tokens * 10 / 1e6 + self.total_output_tokens * 30 / 1e6\n",
    "        return self.total_input_tokens * 30 / 1e6 + self.total_output_tokens * 60 / 1e6\n",
    "\n",
    "    def reset_history(self):\n",
    "        self.action_history = []\n",
    "        self.total_input_tokens = 0\n",
    "        self.total_output_tokens = 0\n",
    "\n",
    "\n",
    "print(f\"OpenAIPlayer loaded! (available: {OPENAI_AVAILABLE})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NrBtpub8LZK"
   },
   "outputs": [],
   "source": [
    "# ============= Hand Result & Metrics =============\n",
    "\n",
    "@dataclass\n",
    "class HandResult:\n",
    "    hand_id: int\n",
    "    player_names: List[str]\n",
    "    starting_stacks: List[int]\n",
    "    ending_stacks: List[int]\n",
    "    chip_deltas: List[int]\n",
    "    hole_cards: Dict[str, Tuple[str, str]]\n",
    "    board: List[str]\n",
    "    winner_names: List[str]\n",
    "    pot_size: int\n",
    "\n",
    "\n",
    "class MetricsCollector:\n",
    "    def __init__(self, session_id: str = None):\n",
    "        self.session_id = session_id or f\"session_{int(time.time())}\"\n",
    "        self.hand_results: List[HandResult] = []\n",
    "        self.session_start = time.time()\n",
    "        self.player_summaries = {}\n",
    "\n",
    "    def log_hand(self, result: HandResult):\n",
    "        self.hand_results.append(result)\n",
    "\n",
    "    def finalize_session(self, player_stats: Dict[str, dict], cumulative_deltas: Dict[str, int] = None):\n",
    "        \"\"\"Finalize session and compute BB/100 metrics.\n",
    "\n",
    "        Args:\n",
    "            player_stats: Stats from each player\n",
    "            cumulative_deltas: Total chip deltas across all hands (for reset-stack mode)\n",
    "        \"\"\"\n",
    "        duration = time.time() - self.session_start\n",
    "        total_hands = len(self.hand_results)\n",
    "\n",
    "        player_names = set()\n",
    "        for hr in self.hand_results:\n",
    "            player_names.update(hr.player_names)\n",
    "\n",
    "        for name in player_names:\n",
    "            hands_played = hands_won = total_chip_delta = 0\n",
    "            for hr in self.hand_results:\n",
    "                if name in hr.player_names:\n",
    "                    idx = hr.player_names.index(name)\n",
    "                    hands_played += 1\n",
    "                    total_chip_delta += hr.chip_deltas[idx]\n",
    "                    if name in hr.winner_names:\n",
    "                        hands_won += 1\n",
    "\n",
    "            # Use cumulative_deltas if provided (more accurate for reset-stack mode)\n",
    "            if cumulative_deltas and name in cumulative_deltas:\n",
    "                total_chip_delta = cumulative_deltas[name]\n",
    "\n",
    "            bb_per_100 = (total_chip_delta / hands_played * 100 / BIG_BLIND) if hands_played > 0 else 0\n",
    "            mbb_per_hand = bb_per_100 * 10  # milli-BB per hand\n",
    "\n",
    "            self.player_summaries[name] = {\n",
    "                \"hands_played\": hands_played,\n",
    "                \"hands_won\": hands_won,\n",
    "                \"win_rate\": hands_won / hands_played if hands_played > 0 else 0,\n",
    "                \"total_chip_delta\": total_chip_delta,\n",
    "                \"bb_per_100\": bb_per_100,\n",
    "                \"mbb_per_hand\": mbb_per_hand,\n",
    "                **player_stats.get(name, {}),\n",
    "            }\n",
    "\n",
    "        self.duration = duration\n",
    "        self.total_hands = total_hands\n",
    "\n",
    "\n",
    "print(\"Metrics loaded with BB/100 and mBB/hand!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nchsOdm98LZK"
   },
   "outputs": [],
   "source": [
    "# ============= Hand Logger =============\n",
    "\n",
    "SUIT_SYMBOLS_LOG = {\"c\": \"\u2663\", \"d\": \"\u2666\", \"h\": \"\u2665\", \"s\": \"\u2660\"}\n",
    "\n",
    "\n",
    "class HandLogger:\n",
    "    \"\"\"Logs sampled poker hands to a file in a pretty format.\"\"\"\n",
    "\n",
    "    def __init__(self, log_dir: str = \"logs\", sample_rate: int = 100):\n",
    "        self.log_dir = log_dir\n",
    "        self.sample_rate = sample_rate\n",
    "        self.session_file: Optional[str] = None\n",
    "        self._current_hand: Optional[Dict] = None\n",
    "\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        self.session_file = os.path.join(log_dir, f\"poker_session_{timestamp}.log\")\n",
    "\n",
    "    def should_log(self, hand_num: int) -> bool:\n",
    "        return hand_num % self.sample_rate == 0\n",
    "\n",
    "    def start_hand(self, hand_num, player_names, stacks, hole_cards, button_pos, sb_pos, bb_pos, blinds):\n",
    "        if not self.should_log(hand_num):\n",
    "            self._current_hand = None\n",
    "            return\n",
    "        self._current_hand = {\n",
    "            \"hand_num\": hand_num, \"timestamp\": datetime.now().isoformat(),\n",
    "            \"player_names\": player_names, \"stacks\": stacks.copy(),\n",
    "            \"hole_cards\": hole_cards, \"button_pos\": button_pos,\n",
    "            \"sb_pos\": sb_pos, \"bb_pos\": bb_pos, \"blinds\": blinds,\n",
    "            \"streets\": [], \"current_street\": None, \"board\": [],\n",
    "            \"final_stacks\": None, \"winners\": [],\n",
    "        }\n",
    "\n",
    "    def start_street(self, street_name: str, board: List[str]):\n",
    "        if self._current_hand is None:\n",
    "            return\n",
    "        self._current_hand[\"current_street\"] = {\"name\": street_name, \"board\": [str(c) for c in board], \"actions\": []}\n",
    "        self._current_hand[\"board\"] = [str(c) for c in board]\n",
    "\n",
    "    def log_action(self, player_idx: int, player_name: str, action_str: str):\n",
    "        if self._current_hand is None or self._current_hand[\"current_street\"] is None:\n",
    "            return\n",
    "        self._current_hand[\"current_street\"][\"actions\"].append({\n",
    "            \"player_idx\": player_idx, \"player_name\": player_name, \"action\": action_str,\n",
    "        })\n",
    "\n",
    "    def end_street(self):\n",
    "        if self._current_hand is None or self._current_hand[\"current_street\"] is None:\n",
    "            return\n",
    "        self._current_hand[\"streets\"].append(self._current_hand[\"current_street\"])\n",
    "        self._current_hand[\"current_street\"] = None\n",
    "\n",
    "    def end_hand(self, final_stacks: List[int], winners: List[int], chips_won: int):\n",
    "        if self._current_hand is None:\n",
    "            return\n",
    "        if self._current_hand[\"current_street\"] is not None:\n",
    "            self.end_street()\n",
    "        self._current_hand[\"final_stacks\"] = final_stacks\n",
    "        self._current_hand[\"winners\"] = winners\n",
    "        self._current_hand[\"chips_won\"] = chips_won\n",
    "        self._write_hand()\n",
    "        self._current_hand = None\n",
    "\n",
    "    def _format_card(self, card: str) -> str:\n",
    "        card_str = str(card)\n",
    "        if \"(\" in card_str and \")\" in card_str:\n",
    "            start = card_str.rfind(\"(\") + 1\n",
    "            end = card_str.rfind(\")\")\n",
    "            card_str = card_str[start:end]\n",
    "        if len(card_str) >= 2:\n",
    "            rank = card_str[:-1].upper()\n",
    "            suit = card_str[-1].lower()\n",
    "            return f\"{rank}{SUIT_SYMBOLS_LOG.get(suit, suit)}\"\n",
    "        return card_str\n",
    "\n",
    "    def _format_cards(self, cards: List) -> str:\n",
    "        if not cards:\n",
    "            return \"[ ]\"\n",
    "        return \"[\" + \" \".join(self._format_card(c) for c in cards) + \"]\"\n",
    "\n",
    "    def _pad_line(self, content: str, width: int = 58) -> str:\n",
    "        padding = max(0, width - len(content))\n",
    "        return f\"\u2551{content}\" + \" \" * padding + \"\u2551\"\n",
    "\n",
    "    def _write_hand(self):\n",
    "        if self._current_hand is None:\n",
    "            return\n",
    "        h = self._current_hand\n",
    "        lines = [\"\", \"\u2554\" + \"\u2550\" * 58 + \"\u2557\"]\n",
    "        lines.append(f\"\u2551  \ud83c\udfb4 HAND #{h['hand_num']:>4}  \u2502  {h['timestamp'][:19]}  \u2551\")\n",
    "        lines.append(\"\u2560\" + \"\u2550\" * 58 + \"\u2563\")\n",
    "        lines.append(\"\u2551  PLAYERS\" + \" \" * 49 + \"\u2551\")\n",
    "        lines.append(\"\u255f\" + \"\u2500\" * 58 + \"\u2562\")\n",
    "\n",
    "        for i, name in enumerate(h[\"player_names\"]):\n",
    "            pos_tag = \" [BTN]\" if i == h[\"button_pos\"] else \" [SB]\" if i == h[\"sb_pos\"] else \" [BB]\" if i == h[\"bb_pos\"] else \"\"\n",
    "            hole = self._format_cards(h[\"hole_cards\"][i]) if h[\"hole_cards\"][i] else \"[?? ??]\"\n",
    "            stack_str = f\"${h['stacks'][i]:,}\"\n",
    "            line = f\"  {name[:12]:<12} {hole:<12} {stack_str:>10}{pos_tag:<8}\"\n",
    "            lines.append(self._pad_line(line))\n",
    "\n",
    "        lines.append(\"\u2560\" + \"\u2550\" * 58 + \"\u2563\")\n",
    "        sb, bb = h[\"blinds\"]\n",
    "        lines.append(self._pad_line(f\"  Blinds: ${sb}/${bb}\"))\n",
    "        lines.append(\"\u2560\" + \"\u2550\" * 58 + \"\u2563\")\n",
    "\n",
    "        for street in h[\"streets\"]:\n",
    "            board_str = self._format_cards(street[\"board\"]) if street[\"board\"] else \"\"\n",
    "            lines.append(self._pad_line(f\"  \u25b6 {street['name'].upper()} {board_str}\"))\n",
    "            lines.append(\"\u255f\" + \"\u2500\" * 58 + \"\u2562\")\n",
    "            for action in street[\"actions\"]:\n",
    "                lines.append(self._pad_line(f\"    {action['player_name'][:12]:<12}: {action['action']}\"))\n",
    "            if not street[\"actions\"]:\n",
    "                lines.append(self._pad_line(\"    (no actions)\"))\n",
    "            lines.append(\"\u255f\" + \"\u2500\" * 58 + \"\u2562\")\n",
    "\n",
    "        if h[\"board\"]:\n",
    "            lines.append(self._pad_line(f\"  Final Board: {self._format_cards(h['board'])}\"))\n",
    "            lines.append(\"\u2560\" + \"\u2550\" * 58 + \"\u2563\")\n",
    "\n",
    "        lines.append(\"\u2551  \ud83c\udfc6 RESULTS\" + \" \" * 46 + \"\u2551\")\n",
    "        lines.append(\"\u255f\" + \"\u2500\" * 58 + \"\u2562\")\n",
    "        if h[\"winners\"]:\n",
    "            winner_names = [h[\"player_names\"][w] for w in h[\"winners\"]]\n",
    "            lines.append(self._pad_line(f\"  Winner: {', '.join(winner_names)} (+${h['chips_won']:,})\"))\n",
    "        lines.append(\"\u255f\" + \"\u2500\" * 58 + \"\u2562\")\n",
    "        lines.append(self._pad_line(\"  Final Stacks:\"))\n",
    "        for i, name in enumerate(h[\"player_names\"]):\n",
    "            if h[\"final_stacks\"]:\n",
    "                diff = h[\"final_stacks\"][i] - h[\"stacks\"][i]\n",
    "                diff_str = f\"+{diff}\" if diff > 0 else str(diff)\n",
    "                lines.append(self._pad_line(f\"    {name[:12]:<12}: ${h['final_stacks'][i]:,} ({diff_str})\"))\n",
    "        lines.append(\"\u255a\" + \"\u2550\" * 58 + \"\u255d\")\n",
    "        lines.append(\"\")\n",
    "\n",
    "        with open(self.session_file, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\".join(lines) + \"\\n\")\n",
    "\n",
    "    def log_session_start(self, num_players, starting_stack, blinds, num_hands):\n",
    "        lines = []\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        lines.append(\"\u250c\" + \"\u2500\" * 58 + \"\u2510\")\n",
    "        lines.append(\"\u2502\" + \" \" * 20 + \"\ud83c\udccf POKER SESSION \ud83c\udccf\" + \" \" * 19 + \"\u2502\")\n",
    "        lines.append(\"\u251c\" + \"\u2500\" * 58 + \"\u2524\")\n",
    "        lines.append(f\"\u2502  Started: {timestamp}\" + \" \" * 27 + \"\u2502\")\n",
    "        lines.append(f\"\u2502  Players: {num_players}\" + \" \" * (47 - len(str(num_players))) + \"\u2502\")\n",
    "        lines.append(f\"\u2502  Starting Stack: ${starting_stack:,}\" + \" \" * max(0, 40 - len(str(starting_stack))) + \"\u2502\")\n",
    "        lines.append(f\"\u2502  Blinds: ${blinds[0]}/${blinds[1]}\" + \" \" * max(0, 45 - len(str(blinds[0])) - len(str(blinds[1]))) + \"\u2502\")\n",
    "        lines.append(f\"\u2502  Planned Hands: {num_hands}\" + \" \" * max(0, 41 - len(str(num_hands))) + \"\u2502\")\n",
    "        lines.append(f\"\u2502  Sample Rate: every {self.sample_rate} hands\" + \" \" * max(0, 36 - len(str(self.sample_rate))) + \"\u2502\")\n",
    "        lines.append(\"\u2514\" + \"\u2500\" * 58 + \"\u2518\")\n",
    "        with open(self.session_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\".join(lines) + \"\\n\")\n",
    "\n",
    "    def log_session_end(self, hands_played, final_stacks, player_names, starting_stack):\n",
    "        lines = [\"\"]\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        lines.append(\"\u250c\" + \"\u2500\" * 58 + \"\u2510\")\n",
    "        lines.append(\"\u2502\" + \" \" * 18 + \"\ud83d\udcca SESSION SUMMARY \ud83d\udcca\" + \" \" * 18 + \"\u2502\")\n",
    "        lines.append(\"\u251c\" + \"\u2500\" * 58 + \"\u2524\")\n",
    "        lines.append(f\"\u2502  Ended: {timestamp}\" + \" \" * 29 + \"\u2502\")\n",
    "        lines.append(f\"\u2502  Hands Played: {hands_played}\" + \" \" * max(0, 42 - len(str(hands_played))) + \"\u2502\")\n",
    "        lines.append(\"\u251c\" + \"\u2500\" * 58 + \"\u2524\")\n",
    "        lines.append(\"\u2502  Final Results:\" + \" \" * 42 + \"\u2502\")\n",
    "        for i, name in enumerate(player_names):\n",
    "            diff = final_stacks[i] - starting_stack\n",
    "            diff_str = f\"+{diff}\" if diff > 0 else str(diff)\n",
    "            emoji = \"\ud83c\udfc6\" if diff > 0 else \"\ud83d\udcc9\" if diff < 0 else \"\u2796\"\n",
    "            line = f\"\u2502    {emoji} {name[:12]:<12}: ${final_stacks[i]:,} ({diff_str})\"\n",
    "            lines.append(line + \" \" * max(0, 58 - len(line) + 1) + \"\u2502\")\n",
    "        lines.append(\"\u2514\" + \"\u2500\" * 58 + \"\u2518\")\n",
    "        with open(self.session_file, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\".join(lines) + \"\\n\")\n",
    "        print(f\"\\n\ud83d\udcdd Hand log saved to: {self.session_file}\")\n",
    "\n",
    "\n",
    "# ============= Eval Game with PromptBuilder and Hand Logging =============\n",
    "\n",
    "class EvalPokerGame:\n",
    "    def __init__(self, players, starting_stack=10000, small_blind=50, big_blind=100,\n",
    "                 metrics=None, observability=None, verbose=False, progress_callback=None,\n",
    "                 use_pokergpt_prompt=True, reset_stacks_each_hand=True, log_sample_rate=100):\n",
    "        self.players = players\n",
    "        self.num_players = len(players)\n",
    "        self.starting_stack = starting_stack\n",
    "        self.small_blind = small_blind\n",
    "        self.big_blind = big_blind\n",
    "        self.stacks = [starting_stack] * self.num_players\n",
    "        self.button = 0\n",
    "        self.hand_num = 0\n",
    "        self.metrics = metrics or MetricsCollector()\n",
    "        self.observability = observability\n",
    "        self.verbose = verbose\n",
    "        self.progress_callback = progress_callback\n",
    "        self.use_pokergpt_prompt = use_pokergpt_prompt\n",
    "        self.reset_stacks_each_hand = reset_stacks_each_hand\n",
    "        self.cumulative_deltas = [0] * self.num_players  # Track total winnings across all hands\n",
    "\n",
    "        # PromptBuilder for pokergpt-style prompts\n",
    "        self.prompt_builder = PromptBuilder(big_blind=big_blind)\n",
    "\n",
    "        # Hand logger (samples every Nth hand)\n",
    "        self.logger = HandLogger(log_dir=f\"{OUTPUT_DIR}/logs\", sample_rate=log_sample_rate)\n",
    "\n",
    "    def play_session(self, num_hands: int) -> MetricsCollector:\n",
    "        # Log session start\n",
    "        self.logger.log_session_start(\n",
    "            num_players=self.num_players,\n",
    "            starting_stack=self.starting_stack,\n",
    "            blinds=(self.small_blind, self.big_blind),\n",
    "            num_hands=num_hands,\n",
    "        )\n",
    "\n",
    "        for hand_idx in range(num_hands):\n",
    "            self._play_hand()\n",
    "            if self.progress_callback:\n",
    "                self.progress_callback(hand_idx + 1, num_hands)\n",
    "            # No early termination - always play all hands for BB/100 calculation\n",
    "        self.metrics.finalize_session(\n",
    "            {p.name: p.get_stats() for p in self.players},\n",
    "            cumulative_deltas={self.players[i].name: self.cumulative_deltas[i] for i in range(self.num_players)}\n",
    "        )\n",
    "\n",
    "        # Log session end\n",
    "        player_names = [p.name for p in self.players]\n",
    "        # For reset_stacks mode, final_stacks is starting_stack but cumulative_deltas has real P/L\n",
    "        final_stacks_for_log = [self.starting_stack + self.cumulative_deltas[i] for i in range(self.num_players)]\n",
    "        self.logger.log_session_end(\n",
    "            hands_played=self.hand_num,\n",
    "            final_stacks=final_stacks_for_log,\n",
    "            player_names=player_names,\n",
    "            starting_stack=self.starting_stack,\n",
    "        )\n",
    "\n",
    "        return self.metrics\n",
    "\n",
    "    def _play_hand(self):\n",
    "        self.hand_num += 1\n",
    "        self.button = (self.button + 1) % self.num_players\n",
    "        for p in self.players:\n",
    "            p.set_hand_context(self.hand_num, \"preflop\")\n",
    "\n",
    "        sb_pos = (self.button + 1) % self.num_players\n",
    "        bb_pos = (self.button + 2) % self.num_players\n",
    "        if self.stacks[sb_pos] <= 0 or self.stacks[bb_pos] <= 0:\n",
    "            # Reset stacks if someone is bust (shouldn't happen with reset mode)\n",
    "            self.stacks = [self.starting_stack] * self.num_players\n",
    "\n",
    "        starting_stacks = self.stacks.copy()\n",
    "\n",
    "        # Reset prompt builder for new hand\n",
    "        self.prompt_builder.reset_hand()\n",
    "\n",
    "        try:\n",
    "            state = NoLimitTexasHoldem.create_state(\n",
    "                automations=(Automation.ANTE_POSTING, Automation.BET_COLLECTION, Automation.BLIND_OR_STRADDLE_POSTING,\n",
    "                             Automation.CARD_BURNING, Automation.HOLE_DEALING, Automation.HOLE_CARDS_SHOWING_OR_MUCKING,\n",
    "                             Automation.HAND_KILLING, Automation.CHIPS_PUSHING, Automation.CHIPS_PULLING),\n",
    "                ante_trimming_status=True, raw_antes={-1: 0},\n",
    "                raw_blinds_or_straddles=(self.small_blind, self.big_blind),\n",
    "                min_bet=self.big_blind, raw_starting_stacks=self.stacks.copy(), player_count=self.num_players,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            if self.verbose:\n",
    "                print(f\"Error: {e}\")\n",
    "            return\n",
    "\n",
    "        hole_cards = [(str(state.hole_cards[i][0]), str(state.hole_cards[i][1]))\n",
    "                      if state.hole_cards[i] and len(state.hole_cards[i]) >= 2 else (\"??\", \"??\")\n",
    "                      for i in range(self.num_players)]\n",
    "        dealable = list(state.get_dealable_cards())\n",
    "        random.shuffle(dealable)\n",
    "        deck = dealable\n",
    "        board = []\n",
    "\n",
    "        # Get positions for this hand\n",
    "        positions = [get_position_name(i, self.num_players, self.button) for i in range(self.num_players)]\n",
    "\n",
    "        # Record initial deals in prompt builder\n",
    "        for i in range(self.num_players):\n",
    "            is_sb = i == sb_pos\n",
    "            is_bb = i == bb_pos\n",
    "            blind_note = \"\"\n",
    "            if is_sb:\n",
    "                blind_note = f\"Small Blind {self.small_blind / self.big_blind:.1f} BB\"\n",
    "            elif is_bb:\n",
    "                blind_note = f\"Big Blind {self.big_blind / self.big_blind:.1f} BB\"\n",
    "            # For now, record deals without hero designation (hero changes per action)\n",
    "            self.prompt_builder.action_history.append(\n",
    "                f\"{positions[i]} was dealt hole cards\" + (f\" ({blind_note})\" if blind_note else \"\") + \".\"\n",
    "            )\n",
    "\n",
    "        # Log hand start\n",
    "        player_names = [p.name for p in self.players]\n",
    "        self.logger.start_hand(\n",
    "            hand_num=self.hand_num,\n",
    "            player_names=player_names,\n",
    "            stacks=self.stacks,\n",
    "            hole_cards=hole_cards,\n",
    "            button_pos=self.button,\n",
    "            sb_pos=sb_pos,\n",
    "            bb_pos=bb_pos,\n",
    "            blinds=(self.small_blind, self.big_blind),\n",
    "        )\n",
    "\n",
    "        for street_idx, street in enumerate([\"preflop\", \"flop\", \"turn\", \"river\"]):\n",
    "            if state.status is False:\n",
    "                break\n",
    "            for p in self.players:\n",
    "                p.set_hand_context(self.hand_num, street)\n",
    "\n",
    "            # End previous street in logger\n",
    "            if street_idx > 0:\n",
    "                self.logger.end_street()\n",
    "\n",
    "            if street == \"flop\":\n",
    "                board = [deck.pop(), deck.pop(), deck.pop()]\n",
    "                for c in board:\n",
    "                    try: state.deal_board(c)\n",
    "                    except: pass\n",
    "                self.prompt_builder.record_board([str(c) for c in board])\n",
    "            elif street in (\"turn\", \"river\"):\n",
    "                board.append(deck.pop())\n",
    "                try: state.deal_board(board[-1])\n",
    "                except: pass\n",
    "                self.prompt_builder.record_board([str(c) for c in board])\n",
    "\n",
    "            # Log street start\n",
    "            self.logger.start_street(street, board)\n",
    "\n",
    "            board_strs = [str(c) for c in board]\n",
    "            while state.actor_index is not None:\n",
    "                actor = state.actor_index\n",
    "                player = self.players[actor]\n",
    "                pot = state.total_pot_amount if hasattr(state, 'total_pot_amount') else 0\n",
    "                current_bet = max(state.bets) if state.bets else 0\n",
    "                player_bet = state.bets[actor] if state.bets else 0\n",
    "                to_call = current_bet - player_bet\n",
    "                stack = state.stacks[actor]\n",
    "                position = positions[actor]\n",
    "\n",
    "                # Build pokergpt-style prompt\n",
    "                if self.use_pokergpt_prompt and hasattr(player, 'get_action_with_prompt'):\n",
    "                    # Get min raise (current bet + big blind as simplified rule)\n",
    "                    min_raise = current_bet + self.big_blind if current_bet > 0 else self.big_blind\n",
    "\n",
    "                    prompt_text = self.prompt_builder.build_prompt(\n",
    "                        hero_idx=actor,\n",
    "                        hero_cards=hole_cards[actor],\n",
    "                        board=board_strs,\n",
    "                        stacks=list(state.stacks),\n",
    "                        bets=list(state.bets) if state.bets else [0] * self.num_players,\n",
    "                        pot=pot,\n",
    "                        to_call=to_call,\n",
    "                        min_raise=min_raise,\n",
    "                        button_idx=self.button,\n",
    "                        num_players=self.num_players,\n",
    "                        street=street,\n",
    "                    )\n",
    "                    action = player.get_action_with_prompt(\n",
    "                        prompt_text, hole_cards[actor], board_strs, pot, to_call, stack, position\n",
    "                    )\n",
    "                else:\n",
    "                    action = player.get_action(hole_cards[actor], board_strs, pot, to_call, stack, position, self.num_players)\n",
    "\n",
    "                if self.verbose:\n",
    "                    print(f\"  H{self.hand_num} {street} {player.name}: {action}\")\n",
    "\n",
    "                executed, fallback = self._execute_action(state, action)\n",
    "\n",
    "                # Log action\n",
    "                self.logger.log_action(actor, player.name, str(action))\n",
    "\n",
    "                # Record action in prompt builder for subsequent players\n",
    "                player_label = positions[actor]\n",
    "                if executed == \"fold\":\n",
    "                    self.prompt_builder.record_action(player_label, \"folded\")\n",
    "                elif executed == \"check\":\n",
    "                    self.prompt_builder.record_action(player_label, \"checked\")\n",
    "                elif executed == \"call\":\n",
    "                    self.prompt_builder.record_action(player_label, \"called\", to_call / self.big_blind)\n",
    "                elif executed == \"raise\":\n",
    "                    raise_amount = action.amount if action.amount else stack\n",
    "                    self.prompt_builder.record_action(player_label, \"bet/raised to\", raise_amount / self.big_blind)\n",
    "                elif executed == \"all_in\":\n",
    "                    self.prompt_builder.record_action(player_label, \"went all-in\", stack / self.big_blind)\n",
    "\n",
    "                # Record observability\n",
    "                if self.observability:\n",
    "                    record = player.get_last_record()\n",
    "                    if record:\n",
    "                        self.observability.record_action(player.name, record, executed, fallback)\n",
    "\n",
    "        if hasattr(state, 'stacks'):\n",
    "            for i in range(self.num_players):\n",
    "                self.stacks[i] = state.stacks[i]\n",
    "\n",
    "        chip_deltas = [self.stacks[i] - starting_stacks[i] for i in range(self.num_players)]\n",
    "        winners = [i for i, d in enumerate(chip_deltas) if d > 0]\n",
    "        max_gain = max(chip_deltas) if chip_deltas else 0\n",
    "        winner_names = [self.players[i].name for i in winners]\n",
    "\n",
    "        # Accumulate deltas for BB/100 calculation\n",
    "        for i in range(self.num_players):\n",
    "            self.cumulative_deltas[i] += chip_deltas[i]\n",
    "\n",
    "        # Log hand end\n",
    "        self.logger.end_street()\n",
    "        self.logger.end_hand(final_stacks=self.stacks, winners=winners, chips_won=max_gain)\n",
    "\n",
    "        self.metrics.log_hand(HandResult(\n",
    "            hand_id=self.hand_num, player_names=[p.name for p in self.players],\n",
    "            starting_stacks=starting_stacks, ending_stacks=self.stacks.copy(),\n",
    "            chip_deltas=chip_deltas, hole_cards={p.name: hole_cards[i] for i, p in enumerate(self.players)},\n",
    "            board=[str(c) for c in board], winner_names=winner_names, pot_size=sum(abs(d) for d in chip_deltas if d < 0),\n",
    "        ))\n",
    "\n",
    "        # Reset stacks for next hand (no elimination)\n",
    "        if self.reset_stacks_each_hand:\n",
    "            self.stacks = [self.starting_stack] * self.num_players\n",
    "\n",
    "    def _execute_action(self, state, action: ParsedAction) -> Tuple[str, bool]:\n",
    "        \"\"\"Execute action, return (executed_action_name, used_fallback)\"\"\"\n",
    "        try:\n",
    "            if action.action_type == \"fold\":\n",
    "                state.fold()\n",
    "                return \"fold\", False\n",
    "            elif action.action_type in (\"check\", \"call\"):\n",
    "                state.check_or_call()\n",
    "                return action.action_type, False\n",
    "            elif action.action_type in (\"raise\", \"bet\"):\n",
    "                state.complete_bet_or_raise_to(action.amount)\n",
    "                return \"raise\", False\n",
    "            elif action.action_type == \"all_in\":\n",
    "                actor = state.actor_index\n",
    "                state.complete_bet_or_raise_to(state.stacks[actor] + state.bets[actor])\n",
    "                return \"all_in\", False\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Fallback\n",
    "        try:\n",
    "            state.check_or_call()\n",
    "            return \"call\", True\n",
    "        except:\n",
    "            try:\n",
    "                state.fold()\n",
    "                return \"fold\", True\n",
    "            except:\n",
    "                return \"error\", True\n",
    "\n",
    "\n",
    "print(\"EvalPokerGame loaded with BB/100 tracking (no elimination) and hand logging!\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ============= Unit Tests: Game Mechanics =============\n",
    "print(\"Testing EvalPokerGame with mock players...\")\n",
    "\n",
    "class MockPlayer:\n",
    "    \"\"\"Simple mock player for testing game mechanics.\"\"\"\n",
    "    def __init__(self, name, action_sequence):\n",
    "        self.name = name\n",
    "        self.actions = action_sequence\n",
    "        self.idx = 0\n",
    "        self.action_history = []\n",
    "\n",
    "    def set_hand_context(self, hand_id, street):\n",
    "        pass\n",
    "\n",
    "    def get_action(self, *args, **kwargs):\n",
    "        action = self.actions[self.idx % len(self.actions)]\n",
    "        self.idx += 1\n",
    "        return action\n",
    "\n",
    "    def get_action_with_prompt(self, *args, **kwargs):\n",
    "        return self.get_action(*args, **kwargs)\n",
    "\n",
    "    def get_stats(self):\n",
    "        return {\"total_actions\": self.idx}\n",
    "\n",
    "    def get_last_record(self):\n",
    "        return None\n",
    "\n",
    "# Two players: one always folds preflop, one always calls\n",
    "# PokerKit heads-up: idx 0 = BB, idx 1 = SB (acts first preflop)\n",
    "# Folder at idx 1 (SB) folds first, Caller at idx 0 (BB) wins\n",
    "folder = MockPlayer(\"Folder\", [ParsedAction(\"fold\")])\n",
    "caller = MockPlayer(\"Caller\", [ParsedAction(\"call\")])\n",
    "\n",
    "game = EvalPokerGame(\n",
    "    players=[caller, folder],  # BB, SB order\n",
    "    starting_stack=1000,\n",
    "    small_blind=5,\n",
    "    big_blind=10,\n",
    "    reset_stacks_each_hand=True,\n",
    "    log_sample_rate=10000,  # Effectively disable logging for test\n",
    ")\n",
    "\n",
    "result = game.play_session(5)\n",
    "\n",
    "# Verify game completed\n",
    "assert result.total_hands == 5, f\"Expected 5 hands, got {result.total_hands}\"\n",
    "assert \"Folder\" in result.player_summaries, \"Missing Folder in summaries\"\n",
    "assert \"Caller\" in result.player_summaries, \"Missing Caller in summaries\"\n",
    "\n",
    "# Folder should lose (folding to BB wins for Caller)\n",
    "assert result.player_summaries[\"Caller\"][\"total_chip_delta\"] > 0, \"Caller should be winning\"\n",
    "assert result.player_summaries[\"Folder\"][\"total_chip_delta\"] < 0, \"Folder should be losing\"\n",
    "\n",
    "print(f\"  Folder: {result.player_summaries['Folder']['total_chip_delta']:+} chips\")\n",
    "print(f\"  Caller: {result.player_summaries['Caller']['total_chip_delta']:+} chips\")\n",
    "print(\"\u2713 EvalPokerGame mock test passed!\")\n"
   ],
   "metadata": {
    "id": "yBzUP0S78LZL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ============= Unit Tests: HandLogger =============\n",
    "print(\"Testing HandLogger...\")\n",
    "\n",
    "import tempfile\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    logger = HandLogger(log_dir=tmpdir, sample_rate=5)\n",
    "\n",
    "    # Test sampling logic - should NOT log hands 1,2,3,4\n",
    "    assert not logger.should_log(1), \"Should not log hand 1\"\n",
    "    assert not logger.should_log(2), \"Should not log hand 2\"\n",
    "    assert not logger.should_log(4), \"Should not log hand 4\"\n",
    "\n",
    "    # Should log hands 5, 10, 15...\n",
    "    assert logger.should_log(5), \"Should log hand 5\"\n",
    "    assert logger.should_log(10), \"Should log hand 10\"\n",
    "    assert logger.should_log(100), \"Should log hand 100\"\n",
    "\n",
    "    # Test session file creation\n",
    "    assert logger.session_file is not None, \"Session file not created\"\n",
    "    assert tmpdir in logger.session_file, \"Session file in wrong directory\"\n",
    "\n",
    "    # Test hand logging workflow\n",
    "    logger.log_session_start(2, 10000, (50, 100), 100)\n",
    "    logger.start_hand(5, [\"P1\", \"P2\"], [10000, 10000], [(\"As\", \"Ks\"), (\"Jd\", \"Td\")], 0, 0, 1, (50, 100))\n",
    "    logger.start_street(\"preflop\", [])\n",
    "    logger.log_action(0, \"P1\", \"raises to 300\")\n",
    "    logger.log_action(1, \"P2\", \"calls 300\")\n",
    "    logger.end_street()\n",
    "    logger.end_hand([10200, 9800], [0], 200)\n",
    "\n",
    "    # Verify log file was written\n",
    "    with open(logger.session_file, \"r\") as f:\n",
    "        content = f.read()\n",
    "        assert \"HAND #\" in content, \"Missing hand header\"\n",
    "        assert \"P1\" in content, \"Missing player name\"\n",
    "        assert \"raises\" in content or \"300\" in content, \"Missing action\"\n",
    "\n",
    "print(\"\u2713 HandLogger tests passed!\")"
   ],
   "metadata": {
    "id": "BmIdr56P8LZL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ============= Unit Tests: Metrics Calculation =============\n",
    "print(\"Testing MetricsCollector BB/100 calculation...\")\n",
    "\n",
    "mc = MetricsCollector(\"test_session\")\n",
    "\n",
    "# Log 10 hands where Winner wins 100 chips each hand\n",
    "for i in range(10):\n",
    "    mc.log_hand(HandResult(\n",
    "        hand_id=i,\n",
    "        player_names=[\"Winner\", \"Loser\"],\n",
    "        starting_stacks=[1000, 1000],\n",
    "        ending_stacks=[1100, 900],\n",
    "        chip_deltas=[100, -100],\n",
    "        hole_cards={\"Winner\": (\"As\", \"Ks\"), \"Loser\": (\"2c\", \"7d\")},\n",
    "        board=[\"Ah\", \"Kd\", \"7c\", \"2s\", \"9h\"],\n",
    "        winner_names=[\"Winner\"],\n",
    "        pot_size=200,\n",
    "    ))\n",
    "\n",
    "# Finalize with cumulative deltas (simulating reset-stack mode)\n",
    "mc.finalize_session(\n",
    "    {\"Winner\": {}, \"Loser\": {}},\n",
    "    cumulative_deltas={\"Winner\": 1000, \"Loser\": -1000}  # 10 hands * 100 chips\n",
    ")\n",
    "\n",
    "# BB/100 = (total_delta / hands * 100) / BB\n",
    "# = (1000 / 10 * 100) / 100 = 100 BB/100\n",
    "expected_bb100 = 100.0\n",
    "actual_bb100 = mc.player_summaries[\"Winner\"][\"bb_per_100\"]\n",
    "assert abs(actual_bb100 - expected_bb100) < 0.01, f\"Expected BB/100={expected_bb100}, got {actual_bb100}\"\n",
    "\n",
    "assert mc.player_summaries[\"Loser\"][\"bb_per_100\"] == -100.0, \"Loser BB/100 should be -100\"\n",
    "assert mc.player_summaries[\"Winner\"][\"win_rate\"] == 1.0, \"Winner should have 100% win rate\"\n",
    "assert mc.player_summaries[\"Loser\"][\"win_rate\"] == 0.0, \"Loser should have 0% win rate\"\n",
    "assert mc.player_summaries[\"Winner\"][\"hands_won\"] == 10, \"Winner should have won 10 hands\"\n",
    "\n",
    "print(f\"  Winner: BB/100 = {actual_bb100:+.1f}, Win Rate = {mc.player_summaries['Winner']['win_rate']*100:.0f}%\")\n",
    "print(f\"  Loser:  BB/100 = {mc.player_summaries['Loser']['bb_per_100']:+.1f}\")\n",
    "print(\"\u2713 MetricsCollector tests passed!\")"
   ],
   "metadata": {
    "id": "c3fByxtV8LZL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLVFWp5v8LZL"
   },
   "source": [
    "## 5. Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R6mx2IwE8LZL"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def load_transformers_model(name: str, model_id: str):\n",
    "    \"\"\"Load a HuggingFace model at full weight (FP16).\"\"\"\n",
    "    print(f\"Loading {name}: {model_id} (FP16 - full weight)...\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float16,\n",
    "    )\n",
    "\n",
    "    allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "    print(f\"  Loaded. VRAM: {allocated:.1f}GB\")\n",
    "\n",
    "    return TransformersPlayer(name, model, tokenizer)\n",
    "\n",
    "\n",
    "def unload_model(player):\n",
    "    \"\"\"Unload model to free VRAM.\"\"\"\n",
    "    if hasattr(player, 'model'):\n",
    "        del player.model\n",
    "        del player.tokenizer\n",
    "    del player\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"  Model unloaded. VRAM: {torch.cuda.memory_allocated() / 1024**3:.1f}GB\")\n",
    "\n",
    "\n",
    "print(\"Model loading functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9v92gfRj8LZL"
   },
   "source": [
    "## 6. Run Tournament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRZqgJN08LZL"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "# Tournament state\n",
    "matchup_results = []\n",
    "champion = None\n",
    "observability = ObservabilityCollector(OUTPUT_DIR)\n",
    "\n",
    "\n",
    "def run_matchup(p1_name: str, p2_name: str, round_name: str) -> Tuple[str, dict]:\n",
    "    \"\"\"Run a single matchup. Returns (winner_name, result_dict).\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{round_name}: {p1_name} vs {p2_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Load players\n",
    "    if MODELS[p1_name][\"type\"] == \"openai\":\n",
    "        p1 = OpenAIPlayer(p1_name, model=MODELS[p1_name].get(\"model\", \"gpt-4\"))\n",
    "    else:\n",
    "        p1 = load_transformers_model(p1_name, MODELS[p1_name][\"model_id\"])\n",
    "\n",
    "    if MODELS[p2_name][\"type\"] == \"openai\":\n",
    "        p2 = OpenAIPlayer(p2_name, model=MODELS[p2_name].get(\"model\", \"gpt-4\"))\n",
    "    else:\n",
    "        p2 = load_transformers_model(p2_name, MODELS[p2_name][\"model_id\"])\n",
    "\n",
    "    # Create game\n",
    "    metrics = MetricsCollector(f\"{round_name}_{p1_name}_vs_{p2_name}\")\n",
    "    pbar = tqdm(total=HANDS_PER_MATCHUP, desc=f\"{p1_name} vs {p2_name}\")\n",
    "\n",
    "    def update_progress(current, total):\n",
    "        pbar.n = current\n",
    "        pbar.refresh()\n",
    "\n",
    "    game = EvalPokerGame(\n",
    "        players=[p1, p2],\n",
    "        starting_stack=STARTING_STACK,\n",
    "        small_blind=SMALL_BLIND,\n",
    "        big_blind=BIG_BLIND,\n",
    "        metrics=metrics,\n",
    "        observability=observability,\n",
    "        verbose=VERBOSE,\n",
    "        progress_callback=update_progress,\n",
    "    )\n",
    "\n",
    "    # Run matchup\n",
    "    result = game.play_session(HANDS_PER_MATCHUP)\n",
    "    pbar.close()\n",
    "\n",
    "    # Write traces\n",
    "    observability.write_traces(f\"{round_name.replace(' ', '_')}\")\n",
    "\n",
    "    # Determine winner\n",
    "    p1_delta = result.player_summaries[p1_name][\"total_chip_delta\"]\n",
    "    p2_delta = result.player_summaries[p2_name][\"total_chip_delta\"]\n",
    "\n",
    "    if p1_delta > p2_delta:\n",
    "        winner = p1_name\n",
    "    elif p2_delta > p1_delta:\n",
    "        winner = p2_name\n",
    "    else:\n",
    "        # Tiebreaker: hands won\n",
    "        p1_wins = result.player_summaries[p1_name][\"hands_won\"]\n",
    "        p2_wins = result.player_summaries[p2_name][\"hands_won\"]\n",
    "        winner = p1_name if p1_wins >= p2_wins else p2_name\n",
    "\n",
    "    # Print result\n",
    "    print(f\"\\n{round_name} Result:\")\n",
    "    print(f\"  {p1_name}: {p1_delta:+} chips (BB/100: {result.player_summaries[p1_name]['bb_per_100']:+.2f})\")\n",
    "    print(f\"  {p2_name}: {p2_delta:+} chips (BB/100: {result.player_summaries[p2_name]['bb_per_100']:+.2f})\")\n",
    "    print(f\"  WINNER: {winner}\")\n",
    "\n",
    "    result_dict = {\n",
    "        \"round\": round_name,\n",
    "        \"player1\": p1_name,\n",
    "        \"player2\": p2_name,\n",
    "        \"player1_chips\": p1_delta,\n",
    "        \"player2_chips\": p2_delta,\n",
    "        \"player1_bb100\": result.player_summaries[p1_name][\"bb_per_100\"],\n",
    "        \"player2_bb100\": result.player_summaries[p2_name][\"bb_per_100\"],\n",
    "        \"winner\": winner,\n",
    "        \"hands_played\": result.total_hands,\n",
    "    }\n",
    "\n",
    "    # Unload models to free VRAM\n",
    "    if MODELS[p1_name][\"type\"] == \"transformers\":\n",
    "        unload_model(p1)\n",
    "    if MODELS[p2_name][\"type\"] == \"transformers\":\n",
    "        unload_model(p2)\n",
    "\n",
    "    return winner, result_dict\n",
    "\n",
    "\n",
    "print(\"Tournament ready to start!\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ============= Pre-flight Checks =============\nprint(\"Pre-flight checks...\")\n\n# Check model configs exist\nrequired_models = [\"Qwen3-SFT\", \"Qwen3-GRPO\", \"Llama3-SFT\"]\nfor name in required_models:\n    assert name in MODELS, f\"Missing model config: {name}\"\n    assert \"model_id\" in MODELS[name] or \"model\" in MODELS[name], f\"Missing model_id/model for {name}\"\n    assert \"type\" in MODELS[name], f\"Missing type for {name}\"\nprint(f\"  \u2713 Model configs validated: {', '.join(required_models)}\")\n\n# Check gauntlet structure\nassert len(GAUNTLET) >= 2, f\"Need at least 2 rounds in gauntlet, got {len(GAUNTLET)}\"\nprint(f\"  \u2713 Gauntlet has {len(GAUNTLET)} rounds\")\n\n# Check output directory\nassert os.path.exists(OUTPUT_DIR), f\"Output dir missing: {OUTPUT_DIR}\"\nprint(f\"  \u2713 Output directory exists: {OUTPUT_DIR}\")\n\n# Check blinds make sense\nassert SMALL_BLIND < BIG_BLIND, f\"Small blind ({SMALL_BLIND}) must be less than big blind ({BIG_BLIND})\"\nassert STARTING_STACK >= BIG_BLIND * 10, f\"Starting stack ({STARTING_STACK}) too small (need at least {BIG_BLIND * 10})\"\nprint(f\"  \u2713 Blinds validated: ${SMALL_BLIND}/${BIG_BLIND}, stack: ${STARTING_STACK}\")\n\n# Check hands per matchup\nassert HANDS_PER_MATCHUP > 0, \"HANDS_PER_MATCHUP must be positive\"\nprint(f\"  \u2713 Hands per matchup: {HANDS_PER_MATCHUP}\")\n\nprint(f\"\\n\u2713 Pre-flight checks passed! Ready to run tournament.\")"
   ],
   "metadata": {
    "id": "7_EgviHR8LZL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmRwPEPP8LZL"
   },
   "outputs": [],
   "source": [
    "# Run the gauntlet tournament\nprint(\"\\n\" + \"=\"*60)\nprint(\"POKER LLM TOURNAMENT\")\nprint(\"=\"*60)\nprint(f\"Format: Gauntlet ({HANDS_PER_MATCHUP} hands per matchup)\")\nprint(f\"Winner: BB/100 (total chip profit)\\n\")\n\n# Round 1: Qwen3-SFT vs Qwen3-GRPO\nr1_winner, r1_result = run_matchup(\"Qwen3-SFT\", \"Qwen3-GRPO\", \"Round 1\")\nmatchup_results.append(r1_result)\n\n# Round 2: Winner R1 vs Llama3-SFT\nr2_winner, r2_result = run_matchup(r1_winner, \"Llama3-SFT\", \"Round 2\")\nmatchup_results.append(r2_result)\n\n# Round 3: Only if your model beat Llama3\nif r2_winner != \"Llama3-SFT\" and os.environ.get(\"OPENAI_API_KEY\"):\n    print(f\"\\n{r2_winner} beat Llama3-SFT! Proceeding to GPT-4 matchup...\")\n    r3_winner, r3_result = run_matchup(r2_winner, \"GPT-4\", \"Round 3\")\n    matchup_results.append(r3_result)\n    champion = r3_winner\nelif r2_winner == \"Llama3-SFT\":\n    print(f\"\\nLlama3-SFT won Round 2. Skipping GPT-4 matchup (cost savings).\")\n    champion = \"Llama3-SFT\"\nelse:\n    print(f\"\\nNo OpenAI API key. Skipping GPT-4 matchup.\")\n    champion = r2_winner\n\nprint(\"\\n\" + \"=\"*60)\nprint(f\"TOURNAMENT CHAMPION: {champion}\")\nprint(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZDjJbIA8LZM"
   },
   "source": [
    "## 7. Observability Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Dzt88s18LZM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Export metrics\n",
    "observability.export_metrics()\n",
    "\n",
    "# Error Rate Summary Table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OBSERVABILITY: ERROR RATES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "error_rows = []\n",
    "for name, m in observability.metrics.items():\n",
    "    error_rows.append({\n",
    "        \"Model\": name,\n",
    "        \"Actions\": m.total_actions,\n",
    "        \"Valid Parse\": m.valid_tag_parses,\n",
    "        \"Regex Fallback\": m.regex_fallback_parses,\n",
    "        \"Default Fallback\": m.default_fallback_parses,\n",
    "        \"Error Rate\": f\"{m.parse_error_rate:.1%}\",\n",
    "        \"Exec Failures\": m.action_execution_failures,\n",
    "    })\n",
    "\n",
    "df_errors = pd.DataFrame(error_rows)\n",
    "print(df_errors.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "df_errors.to_csv(f\"{OUTPUT_DIR}/observability/error_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtGGl8Tt8LZM"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Action Distribution Chart\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# 1. Parse Error Rate\n",
    "ax = axes[0]\n",
    "models = list(observability.metrics.keys())\n",
    "error_rates = [m.parse_error_rate * 100 for m in observability.metrics.values()]\n",
    "colors = [\"green\" if r < 5 else \"orange\" if r < 15 else \"red\" for r in error_rates]\n",
    "ax.bar(models, error_rates, color=colors)\n",
    "ax.set_title(\"Parse Error Rate\", fontsize=14)\n",
    "ax.set_ylabel(\"Error Rate (%)\")\n",
    "ax.set_ylim(0, max(error_rates) * 1.2 if error_rates else 10)\n",
    "\n",
    "# 2. Action Distribution\n",
    "ax = axes[1]\n",
    "action_data = {}\n",
    "for name, m in observability.metrics.items():\n",
    "    total = m.total_actions or 1\n",
    "    action_data[name] = {\n",
    "        \"Fold\": m.fold_count / total * 100,\n",
    "        \"Check\": m.check_count / total * 100,\n",
    "        \"Call\": m.call_count / total * 100,\n",
    "        \"Raise\": m.raise_count / total * 100,\n",
    "        \"All-in\": m.all_in_count / total * 100,\n",
    "    }\n",
    "\n",
    "df_actions = pd.DataFrame(action_data).T\n",
    "df_actions.plot(kind=\"bar\", stacked=True, ax=ax, colormap=\"Set3\")\n",
    "ax.set_title(\"Action Distribution\", fontsize=14)\n",
    "ax.set_ylabel(\"%\")\n",
    "ax.legend(loc=\"upper right\", fontsize=8)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "\n",
    "# 3. Latency\n",
    "ax = axes[2]\n",
    "latency_data = {name: m.latencies for name, m in observability.metrics.items()}\n",
    "ax.boxplot(latency_data.values(), labels=latency_data.keys())\n",
    "ax.set_title(\"Latency Distribution\", fontsize=14)\n",
    "ax.set_ylabel(\"Latency (ms)\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/charts/observability.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alnQ1TeB8LZM"
   },
   "source": [
    "## 8. Tournament Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXWKGwBK8LZM"
   },
   "outputs": [],
   "source": [
    "# Matchup Results Table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TOURNAMENT RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_matchups = pd.DataFrame(matchup_results)\n",
    "print(df_matchups[[\"round\", \"player1\", \"player2\", \"player1_chips\", \"player2_chips\", \"winner\"]].to_string(index=False))\n",
    "\n",
    "# Save\n",
    "df_matchups.to_csv(f\"{OUTPUT_DIR}/matchups.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NpA9kZZm8LZM"
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Chip progression per matchup\n",
    "ax = axes[0]\n",
    "for i, r in enumerate(matchup_results):\n",
    "    x = [i, i]\n",
    "    y = [r[\"player1_chips\"], r[\"player2_chips\"]]\n",
    "    colors = [\"green\" if c > 0 else \"red\" for c in y]\n",
    "    ax.bar([f\"{r['player1']}\\n({r['round']})\", f\"{r['player2']}\\n({r['round']})\"],\n",
    "           [r[\"player1_chips\"], r[\"player2_chips\"]], color=colors, alpha=0.7)\n",
    "\n",
    "ax.axhline(y=0, color=\"black\", linestyle=\"-\", linewidth=0.5)\n",
    "ax.set_title(\"Chip Results by Matchup\", fontsize=14)\n",
    "ax.set_ylabel(\"Chip Delta\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=9)\n",
    "\n",
    "# BB/100 comparison\n",
    "ax = axes[1]\n",
    "all_players = set()\n",
    "player_bb100 = {}\n",
    "for r in matchup_results:\n",
    "    if r[\"player1\"] not in player_bb100:\n",
    "        player_bb100[r[\"player1\"]] = []\n",
    "    if r[\"player2\"] not in player_bb100:\n",
    "        player_bb100[r[\"player2\"]] = []\n",
    "    player_bb100[r[\"player1\"]].append(r[\"player1_bb100\"])\n",
    "    player_bb100[r[\"player2\"]].append(r[\"player2_bb100\"])\n",
    "\n",
    "avg_bb100 = {p: sum(v)/len(v) for p, v in player_bb100.items()}\n",
    "colors = [\"green\" if v > 0 else \"red\" for v in avg_bb100.values()]\n",
    "ax.bar(avg_bb100.keys(), avg_bb100.values(), color=colors)\n",
    "ax.axhline(y=0, color=\"black\", linestyle=\"-\", linewidth=0.5)\n",
    "ax.set_title(\"Average BB/100 by Model\", fontsize=14)\n",
    "ax.set_ylabel(\"BB/100\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/charts/tournament_results.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJIvO0aM8LZM"
   },
   "source": [
    "## 9. Blog-Ready Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gv8W8lAq8LZM"
   },
   "outputs": [],
   "source": [
    "# Generate BLOG_SUMMARY.md\n",
    "blog_md = f\"\"\"# Poker LLM Tournament Results\n",
    "\n",
    "## Champion: {champion}\n",
    "\n",
    "### Tournament Bracket\n",
    "| Round | Matchup | Winner | Chip Differential |\n",
    "|-------|---------|--------|-------------------|\n",
    "\"\"\"\n",
    "\n",
    "for r in matchup_results:\n",
    "    winner_chips = r[\"player1_chips\"] if r[\"winner\"] == r[\"player1\"] else r[\"player2_chips\"]\n",
    "    blog_md += f\"| {r['round']} | {r['player1']} vs {r['player2']} | {r['winner']} | {winner_chips:+} |\\n\"\n",
    "\n",
    "blog_md += f\"\"\"\n",
    "### Key Statistics\n",
    "- **Total hands played**: {sum(r['hands_played'] for r in matchup_results)}\n",
    "- **Matchups completed**: {len(matchup_results)}\n",
    "\"\"\"\n",
    "\n",
    "# Add model comparison\n",
    "blog_md += \"\\n### Model Performance\\n\"\n",
    "blog_md += \"| Model | Avg BB/100 | Error Rate |\\n\"\n",
    "blog_md += \"|-------|------------|------------|\\n\"\n",
    "for name, bb in avg_bb100.items():\n",
    "    err = observability.metrics.get(name)\n",
    "    err_rate = f\"{err.parse_error_rate:.1%}\" if err else \"N/A\"\n",
    "    blog_md += f\"| {name} | {bb:+.2f} | {err_rate} |\\n\"\n",
    "\n",
    "blog_md += f\"\"\"\n",
    "### Notable Findings\n",
    "- Champion **{champion}** emerged victorious after {len(matchup_results)} rounds\n",
    "\"\"\"\n",
    "\n",
    "if \"Llama3-SFT\" in [r[\"winner\"] for r in matchup_results if r[\"round\"] == \"Round 2\"]:\n",
    "    blog_md += \"- The PokerBench paper model (Llama3-SFT) proved superior to custom fine-tunes\\n\"\n",
    "else:\n",
    "    blog_md += f\"- Custom fine-tuned model beat the PokerBench benchmark (Llama3-SFT)\\n\"\n",
    "\n",
    "# Write file\n",
    "with open(f\"{OUTPUT_DIR}/BLOG_SUMMARY.md\", \"w\") as f:\n",
    "    f.write(blog_md)\n",
    "\n",
    "print(blog_md)\n",
    "print(f\"\\nSaved to: {OUTPUT_DIR}/BLOG_SUMMARY.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZ38-kg58LZM"
   },
   "outputs": [],
   "source": [
    "# Quotable Stats (for easy copy-paste)\nprint(\"\\n\" + \"=\"*60)\nprint(\"QUOTABLE STATS (copy-paste ready)\")\nprint(\"=\"*60)\n\nprint(f\"Champion: {champion}\")\n\nif len(matchup_results) > 0:\n    final = matchup_results[-1]\n    margin = abs(final[\"player1_chips\"] - final[\"player2_chips\"])\n    print(f\"Final margin: {margin:,} chips ({margin // BIG_BLIND} BB)\")\n\n# Best local model\nlocal_models = [\"Qwen3-SFT\", \"Qwen3-GRPO\"]\nlocal_bb = {m: avg_bb100.get(m, 0) for m in local_models if m in avg_bb100}\nif local_bb:\n    best_local = max(local_bb, key=local_bb.get)\n    print(f\"Best local model: {best_local} (BB/100: {local_bb[best_local]:+.2f})\")\n\n# Error rates\nprint(\"\\nError rates:\")\nfor name, m in sorted(observability.metrics.items(), key=lambda x: x[1].parse_error_rate):\n    print(f\"  {name}: {m.parse_error_rate:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2u9Cob-8LZM"
   },
   "source": [
    "## 10. Export to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKtfXUUR8LZM"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Save tournament.json\n",
    "tournament_data = {\n",
    "    \"champion\": champion,\n",
    "    \"config\": {\n",
    "        \"hands_per_matchup\": HANDS_PER_MATCHUP,\n",
    "        \"starting_stack\": STARTING_STACK,\n",
    "        \"blinds\": f\"{SMALL_BLIND}/{BIG_BLIND}\",\n",
    "        \"gpu\": GPU_NAME,\n",
    "    },\n",
    "    \"matchups\": matchup_results,\n",
    "}\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/tournament.json\", \"w\") as f:\n",
    "    json.dump(tournament_data, f, indent=2)\n",
    "\n",
    "# Copy to Drive\n",
    "drive_path = \"/content/drive/MyDrive/poker_tournament_results\"\n",
    "shutil.copytree(OUTPUT_DIR, drive_path, dirs_exist_ok=True)\n",
    "\n",
    "print(f\"Results exported to Google Drive: {drive_path}/\")\n",
    "print(f\"\\nFiles:\")\n",
    "for f in os.listdir(OUTPUT_DIR):\n",
    "    print(f\"  - {f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}